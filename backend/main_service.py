"""
å¤šæ¨¡æ€ RAG ä¸»æœåŠ¡
æ•´åˆ PDF è§£æã€å›¾åƒåˆ†æã€å‘é‡æ£€ç´¢åŠŸèƒ½ï¼Œå¯¹æ¥å‰ç«¯API
"""
import os
import sys
import uuid
import asyncio
import logging
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path
import tempfile
import shutil
import time

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()  # åŠ è½½ .env æ–‡ä»¶

# ============ é…ç½®æ—¥å¿—ç³»ç»Ÿ ============
# ç®€å•çš„æ—¥å¿—é…ç½®ï¼Œç›´æ¥è¾“å‡ºåˆ°æ§åˆ¶å°
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    stream=sys.stdout
)

# åˆ›å»ºåº”ç”¨æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger("RAG_Service")

from fastapi import FastAPI, File, UploadFile, HTTPException, Form, Request
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from starlette.middleware.base import BaseHTTPMiddleware
import uvicorn

# æ·»åŠ é¡¹ç›®è·¯å¾„
backend_path = Path(__file__).parent
sys.path.insert(0, str(backend_path))
sys.path.insert(0, str(backend_path / "Information-Extraction"))
sys.path.insert(0, str(backend_path / "image_analysis"))

# å¯¼å…¥ç°æœ‰æ¨¡å—
from simple_vlm_analyzer import SimpleVLMAnalyzer, ImageType
from unified.unified_pdf_extraction_service import PDFExtractionService
from qwen_embeddings import QwenEmbeddings
from simple_logger import log_request

# LangChain imports
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.docstore.document import Document
from langchain_openai import ChatOpenAI, OpenAIEmbeddings


# ============ æ•°æ®æ¨¡å‹ ============

class VLMModel:
    GPT_4O = "gpt-4o"
    QWEN_VL = "qwen-vl"
    INTERN_VL = "intern-vl"


class RetrievalStrategy:
    VECTOR = "vector"
    HYBRID = "hybrid"
    TWO_STAGE = "two-stage"


class SearchRequest(BaseModel):
    """æœç´¢è¯·æ±‚"""
    query: str
    model: str = VLMModel.GPT_4O
    strategy: str = RetrievalStrategy.HYBRID
    topK: int = 10
    minSimilarity: float = 0.0  # æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œé»˜è®¤0.0ï¼ˆä¸è¿‡æ»¤ï¼‰
    filters: Optional[Dict[str, Any]] = None


class SearchResult(BaseModel):
    """æœç´¢ç»“æœ"""
    id: str
    fileName: str
    filePath: str
    fileType: str
    similarity: float
    page: Optional[str] = None
    date: str
    snippet: str
    citationNumber: int
    thumbnailType: str
    thumbnailUrl: Optional[str] = None
    previewUrl: Optional[str] = None
    version: str
    structuredData: List[Dict[str, str]]


class SearchResponse(BaseModel):
    """æœç´¢å“åº”"""
    results: List[SearchResult]
    totalCount: int
    queryTime: float
    model: str
    strategy: str


class UploadResponse(BaseModel):
    """ä¸Šä¼ å“åº”"""
    success: bool
    fileId: str
    fileName: str
    message: Optional[str] = None
    detectedImageType: Optional[str] = None  # æ£€æµ‹åˆ°çš„å›¾ç‰‡ç±»å‹


class FollowUpQuestionRequest(BaseModel):
    """è¿½é—®è¯·æ±‚"""
    documentId: str
    question: str
    model: str = VLMModel.GPT_4O


class FollowUpQuestionResponse(BaseModel):
    """è¿½é—®å“åº”"""
    answer: str
    citations: List[int]
    confidence: float


class IntelligentQARequest(BaseModel):
    """æ™ºèƒ½é—®ç­”è¯·æ±‚"""
    question: str
    filters: Optional[Dict[str, Any]] = None  # å¯é€‰çš„è¿‡æ»¤æ¡ä»¶
    top_k: int = 3


class IntelligentQAResponse(BaseModel):
    """æ™ºèƒ½é—®ç­”å“åº”"""
    answer: str
    sources: List[Dict[str, Any]]
    confidence: float
    query_type: str  # exact_query, filter_query, general_query


# ============ å‘é‡æ•°æ®åº“ç®¡ç†å™¨ ============

class VectorStoreManager:
    """å‘é‡æ•°æ®åº“ç®¡ç†å™¨ - ä½¿ç”¨ ChromaDB"""

    def __init__(self, persist_directory: str = "./chroma_db"):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        self.persist_directory = persist_directory
        os.makedirs(persist_directory, exist_ok=True)

        # æ ¹æ®é…ç½®é€‰æ‹© Embedding æ¨¡å‹
        logger.info("åˆå§‹åŒ– Embedding æ¨¡å‹...")
        embedding_type = os.getenv("EMBEDDING_TYPE", "huggingface").lower()

        if embedding_type == "qwen":
            # ä½¿ç”¨é€šä¹‰åƒé—® Embedding
            logger.info("  ä½¿ç”¨é€šä¹‰åƒé—® text-embedding-v4")
            self.embeddings = QwenEmbeddings(
                api_key=os.getenv("DASHSCOPE_API_KEY"),
                base_url=os.getenv("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1"),
                model=os.getenv("EMBEDDING_MODEL", "text-embedding-v4"),
                dimensions=int(os.getenv("EMBEDDING_DIMENSIONS", "1024"))
            )
        else:
            # ä½¿ç”¨ HuggingFace Embeddingï¼ˆé»˜è®¤ï¼Œç¦»çº¿å¯ç”¨ï¼‰
            print("  ä½¿ç”¨ HuggingFace Embedding")
            model_name = os.getenv("EMBEDDING_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
            self.embeddings = HuggingFaceEmbeddings(
                model_name=model_name,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )

        # åˆå§‹åŒ– Chroma
        self.vector_store = Chroma(
            persist_directory=persist_directory,
            embedding_function=self.embeddings,
            collection_name="multimodal_rag"
        )

        # æ–‡æœ¬åˆ†å‰²å™¨
        chunk_size = int(os.getenv("CHUNK_SIZE", "300"))
        chunk_overlap = int(os.getenv("CHUNK_OVERLAP", "100"))

        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " ", ""]
        )

        logger.info(f"âœ“ å‘é‡æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  Embeddingç±»å‹: {embedding_type}")
        logger.info(f"  åˆ†å—å¤§å°: {chunk_size}, é‡å : {chunk_overlap}")

    async def add_document(
        self,
        file_id: str,
        file_name: str,
        file_type: str,
        content: str,
        metadata: Dict[str, Any]
    ) -> int:
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“"""
        print(f"\nğŸ“¥ æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“: {file_name}")

        # åˆ†å‰²æ–‡æœ¬
        chunks = self.text_splitter.split_text(content)
        logger.info(f"  åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")

        # åˆ›å»º Document å¯¹è±¡
        documents = []
        for i, chunk in enumerate(chunks):
            doc_metadata = {
                "file_id": file_id,
                "file_name": file_name,
                "file_type": file_type,
                "chunk_id": i,
                "total_chunks": len(chunks),
                "upload_date": datetime.now().isoformat(),
                **metadata
            }

            documents.append(Document(
                page_content=chunk,
                metadata=doc_metadata
            ))

        # æ·»åŠ åˆ°å‘é‡åº“
        ids = [f"{file_id}_chunk_{i}" for i in range(len(documents))]
        self.vector_store.add_documents(documents, ids=ids)

        logger.info(f"âœ“ æ–‡æ¡£å·²æ·»åŠ åˆ°å‘é‡åº“ï¼Œå…± {len(documents)} ä¸ªå—")
        return len(documents)

    async def search(
        self,
        query: str,
        top_k: int = 10,
        file_type_filter: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """å‘é‡æ£€ç´¢"""
        print(f"\nğŸ” æ‰§è¡Œå‘é‡æ£€ç´¢: {query[:50]}...")

        # æ„å»ºè¿‡æ»¤å™¨
        where_filter = {}
        if file_type_filter:
            where_filter["file_type"] = file_type_filter

        # æ‰§è¡Œæ£€ç´¢
        if where_filter:
            results = self.vector_store.similarity_search_with_score(
                query,
                k=top_k,
                filter=where_filter
            )
        else:
            results = self.vector_store.similarity_search_with_score(
                query,
                k=top_k
            )

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for doc, score in results:
            # ChromaDB ä½¿ç”¨ L2 (æ¬§å‡ é‡Œå¾—è·ç¦») æˆ–ä½™å¼¦è·ç¦»
            # L2 è·ç¦»èŒƒå›´å¯èƒ½å¾ˆå¤§ï¼Œä½™å¼¦è·ç¦»èŒƒå›´æ˜¯ [0, 2]
            #
            # æ–¹æ¡ˆ1ï¼šä½¿ç”¨å€’æ•°å½’ä¸€åŒ–ï¼ˆé€‚ç”¨äºå„ç§è·ç¦»åº¦é‡ï¼‰
            # similarity = 1 / (1 + distance)
            #
            # æ–¹æ¡ˆ2ï¼šä½™å¼¦è·ç¦»è½¬ç›¸ä¼¼åº¦
            # similarity = 1 - (distance / 2)
            #
            # æˆ‘ä»¬ä½¿ç”¨æ–¹æ¡ˆ1ï¼Œå› ä¸ºå®ƒå¯¹ä»»ä½•è·ç¦»éƒ½æœ‰æ•ˆ
            similarity = 1.0 / (1.0 + score)  # è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜

            formatted_results.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "similarity": float(similarity),
                "distance": float(score)  # ä¿ç•™åŸå§‹è·ç¦»ç”¨äºè°ƒè¯•
            })

        logger.info(f"âœ“ æ‰¾åˆ° {len(formatted_results)} ä¸ªç›¸å…³ç»“æœ")

        # ã€è°ƒè¯•ã€‘æ˜¾ç¤ºè·ç¦»å’Œç›¸ä¼¼åº¦çš„å¯¹åº”å…³ç³»
        if formatted_results:
            logger.info(f"  è·ç¦»èŒƒå›´: {min(r['distance'] for r in formatted_results):.4f} ~ {max(r['distance'] for r in formatted_results):.4f}")
            logger.info(f"  ç›¸ä¼¼åº¦èŒƒå›´: {min(r['similarity'] for r in formatted_results):.4f} ~ {max(r['similarity'] for r in formatted_results):.4f}")

        return formatted_results


# ============ ä¸»æœåŠ¡ç±» ============

class MultimodalRAGService:
    """å¤šæ¨¡æ€ RAG ä¸»æœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.pdf_service = PDFExtractionService()
        self.vector_manager = VectorStoreManager()

        # VLM é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        self.vlm_model_url = os.getenv("VLM_MODEL_URL", None)
        self.vlm_api_key = os.getenv("VLM_API_KEY", None)
        self.vlm_model_name = os.getenv("VLM_MODEL_NAME", "gpt-4o")

        # åˆå§‹åŒ– VLM åˆ†æå™¨
        self.vlm_analyzer = SimpleVLMAnalyzer(
            model_url=self.vlm_model_url,
            api_key=self.vlm_api_key,
            model_name=self.vlm_model_name
        )

        # æ–‡ä»¶å­˜å‚¨ç›®å½•
        self.upload_dir = Path("./uploads")
        self.upload_dir.mkdir(exist_ok=True)

        # é¢„è§ˆå›¾å­˜å‚¨
        self.preview_dir = Path("./previews")
        self.preview_dir.mkdir(exist_ok=True)

        print("âœ“ æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        print("="*60 + "\n")

    def _format_extracted_info_to_natural_language(self, info: Dict[str, Any]) -> str:
        """å°†ç»“æ„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€"""
        if not info:
            return ""

        lines = []

        # æ€»ä½“å°ºå¯¸
        if "total_dimensions" in info:
            dims = info["total_dimensions"]
            lines.append(
                f"å»ºç­‘æ€»é•¿åº¦{dims.get('length', 0)}ç±³ï¼Œ"
                f"æ€»å®½åº¦{dims.get('width', 0)}ç±³ï¼Œ"
                f"æ€»é¢ç§¯{dims.get('total_area', 0)}å¹³æ–¹ç±³ã€‚"
            )

        # æˆ¿é—´ä¿¡æ¯
        if "rooms" in info and info["rooms"]:
            room_count = len(info["rooms"])
            lines.append(f"\nè¯¥å¹³é¢å›¾å…±æœ‰{room_count}ä¸ªæˆ¿é—´ï¼š")

            for room in info["rooms"]:
                parts = [f"- {room.get('name', 'æœªå‘½åæˆ¿é—´')}"]

                if "position" in room:
                    parts.append(f"ä½äº{room['position']}")

                if "dimensions" in room and "area" in room["dimensions"]:
                    parts.append(f"ï¼Œé¢ç§¯{room['dimensions']['area']}å¹³æ–¹ç±³")

                if "furniture" in room and room["furniture"]:
                    parts.append(f"ï¼Œé…æœ‰{' '.join(room['furniture'])}")

                lines.append("".join(parts))

        # åŠ¨çº¿ä¿¡æ¯
        if "circulation" in info:
            circ = info["circulation"]
            if "main_path" in circ:
                lines.append(f"\nåŠ¨çº¿è®¾è®¡ï¼š{circ['main_path']}")
            if "layout_type" in circ:
                lines.append(f"å¸ƒå±€ç±»å‹ï¼š{circ['layout_type']}")

        # CAD å›¾çº¸ä¿¡æ¯
        if "drawing_title" in info:
            lines.insert(0, f"å›¾çº¸åç§°ï¼š{info['drawing_title']}")

        if "main_dimensions" in info:
            dims_text = "ï¼Œ".join([f"{k}{v}" for k, v in info["main_dimensions"].items()])
            lines.append(f"\nä¸»è¦å°ºå¯¸ï¼š{dims_text}")

        # æ¶æ„å›¾ä¿¡æ¯
        if "main_components" in info:
            components = info["main_components"]
            lines.append(f"\nä¸»è¦ç»„ä»¶ï¼š{', '.join(components)}")

        if "layers" in info:
            layers = info["layers"]
            lines.append(f"ç³»ç»Ÿå±‚çº§ï¼š{', '.join(layers)}")

        return "\n".join(lines)

    async def _detect_image_type(
        self,
        image_path: Path,
        user_specified_type: Optional[str] = None
    ) -> str:
        """
        æ™ºèƒ½æ£€æµ‹å›¾ç‰‡ç±»å‹

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            user_specified_type: ç”¨æˆ·æŒ‡å®šçš„ç±»å‹ï¼ˆå¦‚æœæœ‰ï¼‰

        Returns:
            ImageType æšä¸¾å€¼
        """
        # å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
        if user_specified_type:
            logger.info(f"  ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å›¾ç‰‡ç±»å‹: {user_specified_type}")
            return user_specified_type

        logger.info(f"ğŸ” æ™ºèƒ½æ£€æµ‹å›¾ç‰‡ç±»å‹...")

        # åŸºäºæ–‡ä»¶æ‰©å±•åçš„åˆæ­¥åˆ¤æ–­
        file_ext = image_path.suffix.lower()
        if file_ext in ['.dwg', '.dxf']:
            logger.info(f"  æ ¹æ®æ‰©å±•ååˆ¤æ–­ä¸º: CAD")
            return ImageType.CAD

        # ä½¿ç”¨ VLM è¿›è¡Œæ™ºèƒ½è¯†åˆ«
        try:
            detection_prompt = """è¯·å¿«é€Ÿè¯†åˆ«è¿™å¼ å›¾ç‰‡çš„ç±»å‹ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªï¼š

1. **cad** - CADå·¥ç¨‹åˆ¶é€ å›¾çº¸ï¼ˆåŒ…å«å°ºå¯¸æ ‡æ³¨ã€æŠ€æœ¯å‚æ•°ã€é›¶éƒ¨ä»¶ç»“æ„å›¾ï¼‰
2. **floor_plan** - å®¤å†…å¹³é¢å¸ƒç½®å›¾/å»ºç­‘å¹³é¢å›¾ï¼ˆåŒ…å«æˆ¿é—´å¸ƒå±€ã€å®¶å…·æ‘†æ”¾ã€ç©ºé—´å°ºå¯¸ï¼‰
3. **architecture** - ç ”å‘æ¶æ„å›¾/æµç¨‹å›¾/ç³»ç»Ÿå›¾ï¼ˆåŒ…å«æ¨¡å—ã€ç»„ä»¶ã€æ•°æ®æµã€ä¸šåŠ¡æµç¨‹ï¼‰
4. **technical_doc** - å·¥ä¸šæŠ€æœ¯æ¡£æ¡ˆ/å·¥è‰ºæ–‡ä»¶ï¼ˆåŒ…å«è¡¨æ ¼ã€å·¥è‰ºå‚æ•°ã€æ£€éªŒæŠ¥å‘Šï¼‰

**åˆ¤æ–­ä¾æ®ï¼š**
- å¦‚æœæœ‰å¤§é‡å°ºå¯¸æ ‡æ³¨ã€å‰–é¢å›¾ã€é›¶ä»¶è§†å›¾ â†’ cad
- å¦‚æœæœ‰æˆ¿é—´ã€å®¶å…·ã€é—¨çª—ã€åŠ¨çº¿ â†’ floor_plan
- å¦‚æœæœ‰æµç¨‹å›¾ã€æ¶æ„å›¾ã€ç»„ä»¶å…³ç³»ã€ç®­å¤´è¿æ¥ â†’ architecture
- å¦‚æœæœ‰è¡¨æ ¼ã€å·¥è‰ºæµç¨‹ã€æ£€éªŒæ•°æ® â†’ technical_doc

**è¯·ç›´æ¥è¿”å›ç±»å‹åç§°ï¼ˆå°å†™ï¼‰ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚**"""

            # ä½¿ç”¨è¾ƒå°çš„ token é™åˆ¶å¿«é€Ÿåˆ¤æ–­
            from PIL import Image
            image = Image.open(image_path)
            image_base64 = self.vlm_analyzer.image_to_base64(image, max_size=1000)

            # è°ƒç”¨ VLM API
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        },
                        {
                            "type": "text",
                            "text": detection_prompt
                        }
                    ]
                }
            ]

            response = await self.vlm_analyzer.openai_client.chat.completions.create(
                model=self.vlm_model_name,
                messages=messages,
                max_tokens=50,
                temperature=0.0
            )

            detected_type = response.choices[0].message.content.strip().lower()

            # éªŒè¯è¿”å›çš„ç±»å‹
            valid_types = [ImageType.CAD, ImageType.FLOOR_PLAN, ImageType.ARCHITECTURE, ImageType.TECHNICAL_DOC]
            if detected_type in valid_types:
                logger.info(f"  âœ“ æ™ºèƒ½è¯†åˆ«ç»“æœ: {detected_type}")
                return detected_type
            else:
                logger.warning(f"  âš ï¸ æ— æ³•è¯†åˆ«ç±»å‹: {detected_type}ï¼Œä½¿ç”¨é»˜è®¤ç±»å‹: architecture")
                return ImageType.ARCHITECTURE

        except Exception as e:
            logger.warning(f"  âš ï¸ æ™ºèƒ½è¯†åˆ«å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤ç±»å‹: architecture")
            return ImageType.ARCHITECTURE

    def _generate_pdf_thumbnail(self, pdf_path: Path, file_id: str) -> Path:
        """ç”ŸæˆPDFé¦–é¡µç¼©ç•¥å›¾"""
        import fitz
        from PIL import Image
        import io

        try:
            # æ‰“å¼€PDF
            doc = fitz.open(str(pdf_path))

            # è·å–ç¬¬ä¸€é¡µ
            page = doc[0]

            # æ¸²æŸ“ä¸ºå›¾åƒï¼ˆæé«˜åˆ†è¾¨ç‡ä»¥è·å¾—æ›´æ¸…æ™°çš„ç¼©ç•¥å›¾ï¼‰
            mat = fitz.Matrix(2.0, 2.0)  # 2å€ç¼©æ”¾
            pix = page.get_pixmap(matrix=mat)

            # è½¬æ¢ä¸ºPIL Image
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))

            # åˆ›å»ºç¼©ç•¥å›¾ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
            img.thumbnail((400, 400), Image.Resampling.LANCZOS)

            # ä¿å­˜ç¼©ç•¥å›¾
            thumbnail_path = self.preview_dir / f"{file_id}_thumb.png"
            img.save(thumbnail_path, "PNG", optimize=True)

            doc.close()

            logger.info(f"âœ“ PDFç¼©ç•¥å›¾å·²ç”Ÿæˆ: {thumbnail_path}")
            return thumbnail_path

        except Exception as e:
            logger.error(f"ç”ŸæˆPDFç¼©ç•¥å›¾å¤±è´¥: {e}")
            return None

    async def _analyze_pdf_images(
        self,
        pdf_path: Path,
        extraction_result: Dict[str, Any]
    ) -> str:
        """
        åˆ†æPDFä¸­çš„å›¾ç‰‡é¡µé¢ï¼Œä½¿ç”¨VLMæå–ä¿¡æ¯

        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            extraction_result: PDFæå–ç»“æœ

        Returns:
            å›¾ç‰‡åˆ†æçš„æ–‡æœ¬å†…å®¹
        """
        import fitz
        from PIL import Image
        import io

        logger.info("ğŸ–¼ï¸ å¼€å§‹åˆ†æPDFä¸­çš„å›¾ç‰‡é¡µé¢...")

        image_analysis_results = []

        try:
            doc = fitz.open(str(pdf_path))

            # éå†æ¯ä¸€é¡µ
            for page_num in range(len(doc)):
                page = doc[page_num]

                # è·å–é¡µé¢å›¾ç‰‡
                image_list = page.get_images(full=True)

                # å¦‚æœè¿™ä¸€é¡µæœ‰å›¾ç‰‡ï¼Œæˆ–è€…è¿™ä¸€é¡µä¸»è¦æ˜¯å›¾ç‰‡ï¼ˆæ–‡æœ¬å¾ˆå°‘ï¼‰
                text_length = len(page.get_text().strip())

                # åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡é¡µï¼šæœ‰å›¾ç‰‡ä¸”æ–‡æœ¬å°‘äº100å­—ç¬¦
                if image_list and text_length < 100:
                    logger.info(f"  å‘ç°å›¾ç‰‡é¡µ: ç¬¬ {page_num + 1} é¡µ")

                    # æ¸²æŸ“æ•´é¡µä¸ºå›¾ç‰‡
                    mat = fitz.Matrix(2.0, 2.0)  # 2å€ç¼©æ”¾
                    pix = page.get_pixmap(matrix=mat)

                    # è½¬æ¢ä¸ºPIL Image
                    img_data = pix.tobytes("png")
                    image = Image.open(io.BytesIO(img_data))

                    # æ™ºèƒ½æ£€æµ‹å›¾ç‰‡ç±»å‹
                    # å…ˆä¿å­˜ä¸´æ—¶æ–‡ä»¶ç”¨äºæ£€æµ‹
                    temp_path = self.upload_dir / f"temp_page_{page_num}.png"
                    image.save(temp_path, "PNG")

                    detected_type = await self._detect_image_type(temp_path)

                    # ä½¿ç”¨ VLM åˆ†æ
                    analysis_result = await self.vlm_analyzer.analyze_image(
                        image,
                        question=f"è¿™æ˜¯PDFæ–‡æ¡£ç¬¬{page_num + 1}é¡µçš„å†…å®¹ï¼Œè¯·è¯¦ç»†æè¿°è¿™å¼ å›¾çš„æ‰€æœ‰ä¿¡æ¯ã€‚",
                        image_type=detected_type
                    )

                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if temp_path.exists():
                        temp_path.unlink()

                    # ä¿å­˜åˆ†æç»“æœ
                    image_analysis_results.append({
                        'page': page_num + 1,
                        'type': detected_type,
                        'analysis': analysis_result.answer,
                        'structured_info': analysis_result.extracted_info
                    })

                    logger.info(f"  âœ“ ç¬¬ {page_num + 1} é¡µåˆ†æå®Œæˆ (ç±»å‹: {detected_type})")

            doc.close()

            # æ ¼å¼åŒ–å›¾ç‰‡åˆ†æç»“æœ
            if image_analysis_results:
                formatted_results = "\n\n=== PDFå›¾ç‰‡é¡µé¢åˆ†æ ===\n\n"
                for result in image_analysis_results:
                    formatted_results += f"ã€ç¬¬{result['page']}é¡µ - {result['type']}ã€‘\n"
                    formatted_results += f"{result['analysis']}\n"
                    if result['structured_info']:
                        formatted_results += f"ç»“æ„åŒ–ä¿¡æ¯: {result['structured_info']}\n"
                    formatted_results += "\n"

                logger.info(f"âœ“ PDFå›¾ç‰‡åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(image_analysis_results)} é¡µ")
                return formatted_results
            else:
                logger.info("  æœªå‘ç°éœ€è¦VLMåˆ†æçš„å›¾ç‰‡é¡µé¢")
                return ""

        except Exception as e:
            logger.error(f"âŒ PDFå›¾ç‰‡åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return ""

    async def handle_search(
        self,
        request: SearchRequest
    ) -> SearchResponse:
        """å¤„ç†æœç´¢è¯·æ±‚"""
        import time
        start_time = time.time()

        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ” å¤„ç†æœç´¢è¯·æ±‚")
        logger.info(f"  æŸ¥è¯¢: {request.query}")
        logger.info(f"  æ¨¡å‹: {request.model}")
        logger.info(f"  ç­–ç•¥: {request.strategy}")
        logger.info(f"  TopK: {request.topK}")
        logger.info(f"  æœ€å°ç›¸ä¼¼åº¦: {request.minSimilarity}")
        logger.info(f"{'='*60}")

        # æ‰§è¡Œå‘é‡æ£€ç´¢ - æ£€ç´¢æ›´å¤šchunkä»¥ä¾¿èšåˆ
        vector_results = await self.vector_manager.search(
            query=request.query,
            top_k=request.topK * 3  # æ£€ç´¢3å€æ•°é‡ï¼Œç”¨äºèšåˆåç­›é€‰
        )

        # ã€æ–°å¢ã€‘æŒ‰æ–‡ä»¶èšåˆç»“æœ
        file_results = {}  # {file_id: {metadata, chunks, max_similarity}}

        for result in vector_results:
            metadata = result["metadata"]
            file_id = metadata.get("file_id", "unknown")

            if file_id not in file_results:
                file_results[file_id] = {
                    "metadata": metadata,
                    "chunks": [],
                    "max_similarity": result["similarity"]
                }

            file_results[file_id]["chunks"].append({
                "content": result["content"],
                "similarity": result["similarity"],
                "chunk_id": metadata.get("chunk_id", 0)
            })

            # æ›´æ–°æœ€é«˜ç›¸ä¼¼åº¦
            if result["similarity"] > file_results[file_id]["max_similarity"]:
                file_results[file_id]["max_similarity"] = result["similarity"]

        # ã€æ–°å¢ã€‘æŒ‰æœ€é«˜ç›¸ä¼¼åº¦æ’åºæ–‡ä»¶
        sorted_files = sorted(
            file_results.items(),
            key=lambda x: x[1]["max_similarity"],
            reverse=True
        )

        # ã€è°ƒè¯•ã€‘æ‰“å°ç›¸ä¼¼åº¦ä¿¡æ¯
        if sorted_files:
            logger.info(f"\nğŸ“Š ç›¸ä¼¼åº¦åˆ†å¸ƒ:")
            for i, (file_id, file_data) in enumerate(sorted_files[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                logger.info(f"  [{i}] {file_data['metadata'].get('file_name', 'unknown')}: {file_data['max_similarity']:.6f}")

        # ã€æ–°å¢ã€‘æ ¹æ®ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
        filtered_files = [
            (file_id, file_data)
            for file_id, file_data in sorted_files
            if file_data["max_similarity"] >= request.minSimilarity
        ]

        # ã€æ–°å¢ã€‘åªä¿ç•™ topK ä¸ªæ–‡ä»¶
        final_files = filtered_files[:request.topK]

        logger.info(f"  åŸå§‹æ£€ç´¢: {len(vector_results)} ä¸ªchunk")
        logger.info(f"  èšåˆå»é‡: {len(sorted_files)} ä¸ªæ–‡ä»¶")
        logger.info(f"  ç›¸ä¼¼åº¦è¿‡æ»¤(>={request.minSimilarity}): {len(filtered_files)} ä¸ªæ–‡ä»¶")
        logger.info(f"  æœ€ç»ˆè¿”å›(topK={request.topK}): {len(final_files)} ä¸ªæ–‡ä»¶")

        # æ ¼å¼åŒ–ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
        search_results = []
        for idx, (file_id, file_data) in enumerate(final_files):
            metadata = file_data["metadata"]
            chunks = file_data["chunks"]

            # ç¡®å®šæ–‡ä»¶ç±»å‹
            file_name = metadata.get("file_name", "")
            image_type = metadata.get("image_type", "")

            # æ ¹æ®æ£€æµ‹çš„å›¾ç‰‡ç±»å‹è®¾ç½®æ˜¾ç¤ºç±»å‹
            if image_type:
                file_type_map = {
                    ImageType.CAD: "CADå›¾çº¸",
                    ImageType.FLOOR_PLAN: "å¹³é¢å¸ƒç½®å›¾",
                    ImageType.ARCHITECTURE: "æ¶æ„å›¾",
                    ImageType.TECHNICAL_DOC: "æŠ€æœ¯æ–‡æ¡£"
                }
                file_type = file_type_map.get(image_type, "å›¾ç‰‡")
                thumbnail_type = "image"
            elif file_name.lower().endswith('.pdf'):
                file_type = "PDF"
                thumbnail_type = "pdf"
            elif any(ext in file_name.lower() for ext in ['.dwg', '.dxf']):
                file_type = "CAD"
                thumbnail_type = "cad"
            elif any(ext in file_name.lower() for ext in ['.png', '.jpg', '.jpeg']):
                file_type = "å›¾ç‰‡"
                thumbnail_type = "image"
            else:
                file_type = "å…¶ä»–"
                thumbnail_type = "image"

            # ã€æ–°å¢ã€‘åˆå¹¶å¤šä¸ªchunkçš„å†…å®¹ä½œä¸ºsnippet
            # é€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„chunkä½œä¸ºä¸»è¦snippet
            best_chunk = max(chunks, key=lambda c: c["similarity"])
            snippet = best_chunk["content"][:200]

            # å¦‚æœæœ‰å¤šä¸ªchunkï¼Œæ·»åŠ æç¤º
            if len(chunks) > 1:
                snippet += f"... (å…±{len(chunks)}ä¸ªç›¸å…³ç‰‡æ®µ)"

            # æå–é¡µç ä¿¡æ¯
            page_info = metadata.get("page", "N/A")

            search_result = SearchResult(
                id=file_id,
                fileName=file_name,
                filePath=metadata.get("file_path", f"/files/{file_id}"),
                fileType=file_type,
                similarity=file_data["max_similarity"],
                page=str(page_info) if page_info else None,
                date=metadata.get("upload_date", datetime.now().isoformat())[:10],
                snippet=snippet,
                citationNumber=idx + 1,
                thumbnailType=thumbnail_type,
                thumbnailUrl=f"/api/thumbnail/{file_id}",
                previewUrl=f"/api/preview/{file_id}",
                version=metadata.get("version", "v1.0"),
                structuredData=self._extract_structured_data(metadata)
            )

            search_results.append(search_result)

        query_time = time.time() - start_time

        print(f"\nâœ“ æœç´¢å®Œæˆ")
        logger.info(f"  è¿”å› {len(search_results)} ä¸ªæ–‡æ¡£")
        logger.info(f"  è€—æ—¶: {query_time:.2f}ç§’")

        return SearchResponse(
            results=search_results,
            totalCount=len(search_results),
            queryTime=round(query_time * 1000),  # è½¬æ¢ä¸ºæ¯«ç§’
            model=request.model,
            strategy=request.strategy
        )

    async def handle_upload(
        self,
        file: UploadFile,
        image_type: Optional[str] = None
    ) -> UploadResponse:
        """
        å¤„ç†æ–‡ä»¶ä¸Šä¼ 

        Args:
            file: ä¸Šä¼ çš„æ–‡ä»¶
            image_type: ç”¨æˆ·æŒ‡å®šçš„å›¾ç‰‡ç±»å‹ï¼ˆå¯é€‰ï¼‰
                       æ”¯æŒ: cad, floor_plan, architecture, technical_doc
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“¤ å¤„ç†æ–‡ä»¶ä¸Šä¼ : {file.filename}")
        if image_type:
            logger.info(f"   ç”¨æˆ·æŒ‡å®šç±»å‹: {image_type}")
        logger.info(f"{'='*60}")

        try:
            # ç”Ÿæˆæ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            file_extension = Path(file.filename).suffix.lower()

            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            file_path = self.upload_dir / f"{file_id}{file_extension}"
            content = await file.read()
            with open(file_path, 'wb') as f:
                f.write(content)

            logger.info(f"âœ“ æ–‡ä»¶å·²ä¿å­˜: {file_path}")

            detected_image_type = None  # è®°å½•æ£€æµ‹åˆ°çš„å›¾ç‰‡ç±»å‹

            # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
            if file_extension == '.pdf':
                # PDF æ–‡ä»¶ï¼šä½¿ç”¨å¿«é€Ÿæ¨¡å¼æå–
                extraction_result = await self.pdf_service.extract_fast(
                    str(file_path),
                    original_filename=file.filename
                )

                content_text = extraction_result["markdown"]
                file_type = "PDF"

                # æå–é¡µé¢ä¿¡æ¯
                page_count = extraction_result["metadata"]["total_pages"]

                # ç”ŸæˆPDFé¦–é¡µç¼©ç•¥å›¾
                self._generate_pdf_thumbnail(file_path, file_id)

                # ã€æ–°å¢ã€‘åˆ†æPDFä¸­çš„å›¾ç‰‡é¡µé¢
                pdf_image_analysis = await self._analyze_pdf_images(file_path, extraction_result)
                if pdf_image_analysis:
                    content_text += "\n\n" + pdf_image_analysis
                    logger.info("âœ“ PDFå›¾ç‰‡é¡µé¢å·²æ•´åˆåˆ°å†…å®¹ä¸­")

            elif file_extension in ['.png', '.jpg', '.jpeg', '.dwg', '.dxf']:
                # ã€æ–°å¢ã€‘æ™ºèƒ½æ£€æµ‹å›¾ç‰‡ç±»å‹
                detected_image_type = await self._detect_image_type(file_path, image_type)

                # æ ¹æ®æ£€æµ‹çš„ç±»å‹ç”Ÿæˆåˆé€‚çš„é—®é¢˜
                question_map = {
                    ImageType.CAD: "è¯·è¯¦ç»†æè¿°è¿™å¼ CADå›¾çº¸çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ‰€æœ‰å¯è§çš„æŠ€æœ¯ä¿¡æ¯ã€å°ºå¯¸æ ‡æ³¨ã€é›¶éƒ¨ä»¶ç»“æ„ç­‰ã€‚",
                    ImageType.FLOOR_PLAN: "è¯·è¯¦ç»†æè¿°è¿™å¼ å¹³é¢å¸ƒç½®å›¾ï¼ŒåŒ…æ‹¬æˆ¿é—´å¸ƒå±€ã€å°ºå¯¸ã€å®¶å…·æ‘†æ”¾ã€åŠ¨çº¿ç­‰ä¿¡æ¯ã€‚",
                    ImageType.ARCHITECTURE: "è¯·è¯¦ç»†æè¿°è¿™å¼ æ¶æ„å›¾/æµç¨‹å›¾ï¼ŒåŒ…æ‹¬æ‰€æœ‰ç»„ä»¶ã€æ¨¡å—ã€å…³ç³»å’Œæµç¨‹ã€‚",
                    ImageType.TECHNICAL_DOC: "è¯·è¯¦ç»†æè¿°è¿™ä»½æŠ€æœ¯æ–‡æ¡£ï¼ŒåŒ…æ‹¬æ‰€æœ‰å¯è§çš„å‚æ•°ã€è¡¨æ ¼æ•°æ®ã€å·¥è‰ºä¿¡æ¯ç­‰ã€‚"
                }

                question = question_map.get(detected_image_type, "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾çš„æ‰€æœ‰å†…å®¹ã€‚")

                # å›¾åƒ/CAD æ–‡ä»¶ï¼šä½¿ç”¨ VLM åˆ†æ
                analysis_result = await self.vlm_analyzer.analyze_image(
                    str(file_path),
                    question=question,
                    image_type=detected_image_type
                )

                # ã€ä¼˜åŒ–ã€‘å°†ç»“æ„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€
                natural_language_info = self._format_extracted_info_to_natural_language(
                    analysis_result.extracted_info
                )
                content_text = f"{analysis_result.answer}\n\n{natural_language_info}"

                # ã€æ–°å¢ã€‘æ ¹æ®æ£€æµ‹ç±»å‹è®¾ç½®æ–‡ä»¶ç±»å‹
                file_type_map = {
                    ImageType.CAD: "CADå›¾çº¸",
                    ImageType.FLOOR_PLAN: "å¹³é¢å¸ƒç½®å›¾",
                    ImageType.ARCHITECTURE: "æ¶æ„å›¾",
                    ImageType.TECHNICAL_DOC: "æŠ€æœ¯æ–‡æ¡£"
                }
                file_type = file_type_map.get(detected_image_type, "å›¾ç‰‡")
                page_count = 1

            else:
                raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}")

            # æ·»åŠ åˆ°å‘é‡åº“
            metadata = {
                "file_path": str(file_path),
                "file_extension": file_extension,
                "page_count": page_count,
                "version": "v1.0"
            }

            # å¦‚æœæœ‰æ£€æµ‹åˆ°çš„å›¾ç‰‡ç±»å‹ï¼Œæ·»åŠ åˆ°å…ƒæ•°æ®
            if detected_image_type:
                metadata["image_type"] = detected_image_type

            # ã€æ–°å¢ã€‘å¦‚æœæœ‰åˆ†æç»“æœï¼Œå­˜å‚¨ç»“æ„åŒ–ä¿¡æ¯åˆ°å…ƒæ•°æ®
            if 'analysis_result' in locals():
                # âš ï¸ ChromaDB ä¸æ”¯æŒåµŒå¥—å­—å…¸ï¼Œéœ€è¦åºåˆ—åŒ–
                # å°†å¤æ‚çš„ extracted_info è½¬ä¸º JSON å­—ç¬¦ä¸²
                metadata["extracted_info_json"] = json.dumps(analysis_result.extracted_info, ensure_ascii=False)

                # ã€æ–°å¢ã€‘æå–å…³é”®å­—æ®µåˆ°å…ƒæ•°æ®é¡¶å±‚ï¼ˆä¾¿äºè¿‡æ»¤ï¼‰
                extracted_info = analysis_result.extracted_info
                if "rooms" in extracted_info:
                    metadata["room_count"] = len(extracted_info["rooms"])
                    # ç»Ÿè®¡å§å®¤æ•°é‡
                    bedrooms = [r for r in extracted_info["rooms"] if "å§" in r.get("name", "")]
                    metadata["bedroom_count"] = len(bedrooms)

                if "total_dimensions" in extracted_info:
                    total_dims = extracted_info["total_dimensions"]
                    metadata["total_area"] = float(total_dims.get("total_area", 0))
                    metadata["total_length"] = float(total_dims.get("length", 0))
                    metadata["total_width"] = float(total_dims.get("width", 0))

            chunk_count = await self.vector_manager.add_document(
                file_id=file_id,
                file_name=file.filename,
                file_type=file_type,
                content=content_text,
                metadata=metadata
            )

            print(f"\nâœ“ æ–‡ä»¶ä¸Šä¼ å¹¶ç´¢å¼•å®Œæˆ")
            logger.info(f"  æ–‡ä»¶ID: {file_id}")
            logger.info(f"  æ–‡ä»¶ç±»å‹: {file_type}")
            if detected_image_type:
                logger.info(f"  æ£€æµ‹ç±»å‹: {detected_image_type}")
            logger.info(f"  åˆ†å—æ•°: {chunk_count}")

            return UploadResponse(
                success=True,
                fileId=file_id,
                fileName=file.filename,
                message=f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå·²åˆ†å‰²ä¸º {chunk_count} ä¸ªæ–‡æœ¬å—å¹¶å»ºç«‹ç´¢å¼•",
                detectedImageType=detected_image_type
            )

        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            return UploadResponse(
                success=False,
                fileId="",
                fileName=file.filename,
                message=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"
            )

    async def handle_follow_up_question(
        self,
        request: FollowUpQuestionRequest
    ) -> FollowUpQuestionResponse:
        """å¤„ç†è¿½é—®"""

        # æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
        results = await self.vector_manager.search(
            query=request.question,
            top_k=3
        )

        # è¿‡æ»¤å‡ºæŒ‡å®šæ–‡æ¡£çš„ç»“æœ
        doc_results = [r for r in results if r["metadata"].get("file_id") == request.documentId]

        if not doc_results:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŒ‡å®šæ–‡æ¡£ï¼Œä½¿ç”¨æ‰€æœ‰ç»“æœ
            doc_results = results

        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([r["content"] for r in doc_results[:3]])

        # ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”
        try:
            from langchain_openai import ChatOpenAI

            llm = ChatOpenAI(
                model_name=self.vlm_model_name,
                api_key=self.vlm_api_key,
                base_url=self.vlm_model_url,
                temperature=0.3
            )

            prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{request.question}

è¯·ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ï¼Œå¹¶æŒ‡å‡ºå›ç­”ä¾æ®çš„å†…å®¹æ¥è‡ªå“ªäº›éƒ¨åˆ†ã€‚"""

            response = await llm.ainvoke(prompt)
            answer = response.content

            # æå–å¼•ç”¨
            citations = [i + 1 for i in range(len(doc_results))]

            logger.info(f"âœ“ å›ç­”ç”Ÿæˆå®Œæˆ")

            return FollowUpQuestionResponse(
                answer=answer,
                citations=citations,
                confidence=0.85
            )

        except Exception as e:
            logger.error(f"âŒ å›ç­”ç”Ÿæˆå¤±è´¥: {e}")
            return FollowUpQuestionResponse(
                answer="æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚",
                citations=[],
                confidence=0.0
            )

    def _extract_structured_data(self, metadata: Dict[str, Any]) -> List[Dict[str, str]]:
        """ä»å…ƒæ•°æ®æå–ç»“æ„åŒ–æ•°æ®"""
        structured_data = []

        if "page_count" in metadata:
            structured_data.append({
                "label": "é¡µæ•°",
                "value": str(metadata["page_count"])
            })

        if "version" in metadata:
            structured_data.append({
                "label": "ç‰ˆæœ¬",
                "value": metadata["version"]
            })

        if "upload_date" in metadata:
            structured_data.append({
                "label": "ä¸Šä¼ æ—¥æœŸ",
                "value": metadata["upload_date"][:10]
            })

        return structured_data

    async def handle_intelligent_qa(
        self,
        request: IntelligentQARequest
    ) -> IntelligentQAResponse:
        """
        æ™ºèƒ½é—®ç­” - ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜

        æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†ç­–ç•¥ï¼š
        1. ç²¾ç¡®æŸ¥è¯¢ï¼šä»å…ƒæ•°æ®ç›´æ¥æå–ç­”æ¡ˆï¼ˆå¦‚ï¼š"æœ‰å‡ ä¸ªå§å®¤"ï¼‰
        2. è¿‡æ»¤æŸ¥è¯¢ï¼šå…ˆè¿‡æ»¤å†æ£€ç´¢ï¼ˆå¦‚ï¼š"æ‰¾3ä¸ªå§å®¤çš„æˆ·å‹"ï¼‰
        3. ä¸€èˆ¬æŸ¥è¯¢ï¼šå‘é‡æ£€ç´¢ + LLMç”Ÿæˆç­”æ¡ˆ
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ¤– æ™ºèƒ½é—®ç­”")
        logger.info(f"  é—®é¢˜: {request.question}")
        logger.info(f"{'='*60}")

        # 1. åˆ†ç±»é—®é¢˜ç±»å‹
        query_type = self._classify_question(request.question)
        logger.info(f"  é—®é¢˜ç±»å‹: {query_type}")

        # 2. æ ¹æ®é—®é¢˜ç±»å‹å¤„ç†
        if query_type == "exact_query":
            # ç²¾ç¡®æŸ¥è¯¢ï¼šä»å…ƒæ•°æ®ç›´æ¥æå–
            answer, sources, confidence = await self._handle_exact_query(request.question, request.top_k)

        elif query_type == "filter_query":
            # è¿‡æ»¤æŸ¥è¯¢ï¼šæ™ºèƒ½è¿‡æ»¤ + æ£€ç´¢
            answer, sources, confidence = await self._handle_filter_query(request.question, request.top_k)

        else:
            # ä¸€èˆ¬æŸ¥è¯¢ï¼šå‘é‡æ£€ç´¢ + LLM
            answer, sources, confidence = await self._handle_general_query(request.question, request.top_k)

        logger.info(f"âœ“ ç­”æ¡ˆå·²ç”Ÿæˆ")
        logger.info(f"  ç½®ä¿¡åº¦: {confidence:.2f}")
        logger.info(f"  æ¥æºæ•°: {len(sources)}")

        return IntelligentQAResponse(
            answer=answer,
            sources=sources,
            confidence=confidence,
            query_type=query_type
        )

    def _classify_question(self, question: str) -> str:
        """åˆ†ç±»é—®é¢˜ç±»å‹"""
        question_lower = question.lower()

        # ç²¾ç¡®æŸ¥è¯¢å…³é”®è¯
        exact_keywords = ["å‡ ä¸ª", "å¤šå°‘ä¸ª", "æœ‰å¤šå°‘", "é¢ç§¯", "å°ºå¯¸", "é•¿åº¦", "å®½åº¦", "å¤šå¤§", "å¤šé•¿"]
        if any(kw in question for kw in exact_keywords):
            return "exact_query"

        # è¿‡æ»¤æŸ¥è¯¢å…³é”®è¯
        filter_keywords = ["æ‰¾", "æŸ¥æ‰¾", "ç­›é€‰", "ç¬¦åˆ", "æ»¡è¶³", "å¤§äº", "å°äº", "è‡³å°‘"]
        if any(kw in question for kw in filter_keywords):
            return "filter_query"

        return "general_query"

    async def _handle_exact_query(
        self,
        question: str,
        top_k: int
    ) -> tuple[str, List[Dict[str, Any]], float]:
        """å¤„ç†ç²¾ç¡®æŸ¥è¯¢ - ä»å…ƒæ•°æ®ç›´æ¥æå–ç­”æ¡ˆ"""

        # å‘é‡æ£€ç´¢æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£
        vector_results = await self.vector_manager.search(
            query=question,
            top_k=top_k
        )

        if not vector_results:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚", [], 0.0

        top_result = vector_results[0]
        metadata = top_result["metadata"]

        # ä» JSON å­—ç¬¦ä¸²è§£æ extracted_info
        extracted_info = {}
        if "extracted_info_json" in metadata:
            try:
                extracted_info = json.loads(metadata["extracted_info_json"])
            except:
                pass

        # æ ¹æ®é—®é¢˜æå–ç­”æ¡ˆ
        answer_parts = []

        # å¤„ç†å§å®¤ç›¸å…³é—®é¢˜
        if "å§å®¤" in question or "æˆ¿é—´" in question:
            if "rooms" in extracted_info:
                rooms = extracted_info["rooms"]
                bedrooms = [r for r in rooms if "å§" in r.get("name", "")]

                if bedrooms:
                    answer_parts.append(f"è¿™å¼ {metadata.get('file_type', 'å›¾çº¸')}æœ‰{len(bedrooms)}ä¸ªå§å®¤ï¼š")
                    for i, room in enumerate(bedrooms, 1):
                        room_text = f"{i}. {room['name']}"
                        if "dimensions" in room and "area" in room["dimensions"]:
                            room_text += f" - {room['dimensions']['area']}å¹³æ–¹ç±³"
                        if "position" in room:
                            room_text += f"ï¼ˆ{room['position']}ï¼‰"
                        answer_parts.append(room_text)
                else:
                    answer_parts.append("æœªæ‰¾åˆ°å§å®¤ä¿¡æ¯ã€‚")

        # å¤„ç†é¢ç§¯ç›¸å…³é—®é¢˜
        elif "é¢ç§¯" in question or "å¤šå¤§" in question:
            if "total_area" in metadata:
                total_area = metadata["total_area"]
                answer_parts.append(f"æ€»é¢ç§¯ä¸º {total_area} å¹³æ–¹ç±³")
            elif "total_dimensions" in extracted_info:
                total_area = extracted_info["total_dimensions"].get("total_area")
                answer_parts.append(f"æ€»é¢ç§¯ä¸º {total_area} å¹³æ–¹ç±³")
            else:
                answer_parts.append("æœªæ‰¾åˆ°é¢ç§¯ä¿¡æ¯ã€‚")

        # å¤„ç†å°ºå¯¸ç›¸å…³é—®é¢˜
        elif "å°ºå¯¸" in question or "é•¿åº¦" in question or "å®½åº¦" in question:
            if "total_dimensions" in extracted_info:
                dims = extracted_info["total_dimensions"]
                answer_parts.append(
                    f"å»ºç­‘å°ºå¯¸ï¼šé•¿ {dims.get('length')} ç±³ï¼Œå®½ {dims.get('width')} ç±³ï¼Œ"
                    f"æ€»é¢ç§¯ {dims.get('total_area')} å¹³æ–¹ç±³"
                )
            else:
                answer_parts.append("æœªæ‰¾åˆ°å°ºå¯¸ä¿¡æ¯ã€‚")

        # é»˜è®¤å›ç­”
        if not answer_parts:
            answer_parts.append("æ ¹æ®æ–‡æ¡£å†…å®¹ï¼š")
            answer_parts.append(top_result["content"][:300])

        # æ·»åŠ æ¥æº
        answer_parts.append(f"\nğŸ“„ æ¥æºï¼š{metadata.get('file_name', 'æœªçŸ¥æ–‡ä»¶')}")

        answer = "\n".join(answer_parts)

        # æ„å»ºæ¥æºä¿¡æ¯
        sources = [{
            "file_id": metadata.get("file_id"),
            "file_name": metadata.get("file_name"),
            "file_type": metadata.get("file_type"),
            "similarity": top_result["similarity"]
        }]

        confidence = top_result["similarity"]

        return answer, sources, confidence

    async def _handle_filter_query(
        self,
        question: str,
        top_k: int
    ) -> tuple[str, List[Dict[str, Any]], float]:
        """å¤„ç†è¿‡æ»¤æŸ¥è¯¢ - æ™ºèƒ½è¿‡æ»¤ + æ£€ç´¢"""

        # è§£æè¿‡æ»¤æ¡ä»¶
        filters = self._parse_filter_conditions(question)
        logger.info(f"  è§£æçš„è¿‡æ»¤æ¡ä»¶: {filters}")

        # TODO: å®ç°å¸¦è¿‡æ»¤çš„æ£€ç´¢ï¼ˆéœ€è¦ ChromaDB æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤ï¼‰
        # æš‚æ—¶ä½¿ç”¨æ™®é€šæ£€ç´¢åè¿‡æ»¤
        vector_results = await self.vector_manager.search(
            query=question,
            top_k=top_k * 3  # æ£€ç´¢æ›´å¤šç»“æœç”¨äºè¿‡æ»¤
        )

        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        filtered_results = []
        for result in vector_results:
            metadata = result["metadata"]

            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆè¿‡æ»¤æ¡ä»¶
            if self._match_filters(metadata, filters):
                filtered_results.append(result)

            if len(filtered_results) >= top_k:
                break

        if not filtered_results:
            return f"æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç»“æœã€‚", [], 0.0

        # ç”Ÿæˆç­”æ¡ˆ
        answer_parts = [f"æ‰¾åˆ° {len(filtered_results)} ä¸ªç¬¦åˆæ¡ä»¶çš„ç»“æœï¼š\n"]

        for i, result in enumerate(filtered_results, 1):
            metadata = result["metadata"]

            # è§£æ extracted_info
            extracted_info = {}
            if "extracted_info_json" in metadata:
                try:
                    extracted_info = json.loads(metadata["extracted_info_json"])
                except:
                    pass

            answer_parts.append(f"\n{i}. {metadata.get('file_name')}")

            # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
            if "total_area" in metadata:
                answer_parts.append(f"   - æ€»é¢ç§¯ï¼š{metadata['total_area']}å¹³æ–¹ç±³")

            if "bedroom_count" in metadata:
                answer_parts.append(f"   - å§å®¤æ•°ï¼š{metadata['bedroom_count']}ä¸ª")

            if "room_count" in metadata:
                answer_parts.append(f"   - æˆ¿é—´æ•°ï¼š{metadata['room_count']}ä¸ª")

        answer = "\n".join(answer_parts)

        # æ„å»ºæ¥æºä¿¡æ¯
        sources = [{
            "file_id": r["metadata"].get("file_id"),
            "file_name": r["metadata"].get("file_name"),
            "file_type": r["metadata"].get("file_type"),
            "similarity": r["similarity"]
        } for r in filtered_results]

        confidence = filtered_results[0]["similarity"] if filtered_results else 0.0

        return answer, sources, confidence

    def _parse_filter_conditions(self, question: str) -> Dict[str, Any]:
        """è§£æè¿‡æ»¤æ¡ä»¶"""
        filters = {}

        # è§£ææ•°å­—æ¡ä»¶
        import re

        # å§å®¤æ•°é‡
        bedroom_match = re.search(r'(\d+)\s*ä¸ª?\s*å§å®¤', question)
        if bedroom_match:
            filters["bedroom_count"] = int(bedroom_match.group(1))

        # æˆ¿é—´æ•°é‡
        room_match = re.search(r'(\d+)\s*ä¸ª?\s*æˆ¿é—´', question)
        if room_match:
            filters["room_count"] = int(room_match.group(1))

        # é¢ç§¯èŒƒå›´
        area_match = re.search(r'(\d+)\s*[ä»¥ä¸Šå¤§äº].*?å¹³', question)
        if area_match:
            filters["total_area_gte"] = int(area_match.group(1))

        area_match2 = re.search(r'[å°å°‘äº].*?(\d+)\s*å¹³', question)
        if area_match2:
            filters["total_area_lte"] = int(area_match2.group(1))

        # å›¾çº¸ç±»å‹
        if "å¹³é¢å›¾" in question or "æˆ·å‹" in question:
            filters["image_type"] = ImageType.FLOOR_PLAN

        return filters

    def _match_filters(self, metadata: Dict[str, Any], filters: Dict[str, Any]) -> bool:
        """æ£€æŸ¥å…ƒæ•°æ®æ˜¯å¦åŒ¹é…è¿‡æ»¤æ¡ä»¶"""
        for key, value in filters.items():
            if key == "bedroom_count":
                if metadata.get("bedroom_count", 0) != value:
                    return False

            elif key == "room_count":
                if metadata.get("room_count", 0) != value:
                    return False

            elif key == "total_area_gte":
                if metadata.get("total_area", 0) < value:
                    return False

            elif key == "total_area_lte":
                if metadata.get("total_area", float('inf')) > value:
                    return False

            elif key == "image_type":
                if metadata.get("image_type") != value:
                    return False

        return True

    async def _handle_general_query(
        self,
        question: str,
        top_k: int
    ) -> tuple[str, List[Dict[str, Any]], float]:
        """å¤„ç†ä¸€èˆ¬æŸ¥è¯¢ - å‘é‡æ£€ç´¢ + LLM"""

        # å‘é‡æ£€ç´¢
        vector_results = await self.vector_manager.search(
            query=question,
            top_k=top_k
        )

        if not vector_results:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚", [], 0.0

        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for i, result in enumerate(vector_results, 1):
            metadata = result["metadata"]
            context_parts.append(f"[æ–‡æ¡£{i}] {metadata.get('file_name')}:")
            context_parts.append(result["content"][:500])
            context_parts.append("")

        context = "\n".join(context_parts)

        # ä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        if self.vlm_api_key:
            try:
                from langchain_openai import ChatOpenAI

                llm = ChatOpenAI(
                    model_name=self.vlm_model_name,
                    api_key=self.vlm_api_key,
                    base_url=self.vlm_model_url,
                    temperature=0.3
                )

                prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚"""

                response = await llm.ainvoke(prompt)
                answer = response.content

                # æ·»åŠ æ¥æº
                sources_text = "\n\nğŸ“„ å‚è€ƒæ¥æºï¼š\n"
                for i, result in enumerate(vector_results, 1):
                    sources_text += f"{i}. {result['metadata'].get('file_name')}\n"

                answer += sources_text

            except Exception as e:
                logger.error(f"LLMç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
                answer = f"æ ¹æ®æ£€ç´¢åˆ°çš„å†…å®¹ï¼š\n\n{vector_results[0]['content'][:500]}\n\næ¥æºï¼š{vector_results[0]['metadata'].get('file_name')}"
        else:
            # æ²¡æœ‰é…ç½®LLMï¼Œè¿”å›æœ€ç›¸å…³çš„å†…å®¹
            answer = f"æ ¹æ®æ£€ç´¢åˆ°çš„å†…å®¹ï¼š\n\n{vector_results[0]['content'][:500]}\n\næ¥æºï¼š{vector_results[0]['metadata'].get('file_name')}"

        # æ„å»ºæ¥æºä¿¡æ¯
        sources = [{
            "file_id": r["metadata"].get("file_id"),
            "file_name": r["metadata"].get("file_name"),
            "file_type": r["metadata"].get("file_type"),
            "similarity": r["similarity"]
        } for r in vector_results]

        confidence = vector_results[0]["similarity"]

        return answer, sources, confidence


# ============ è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶ ============

class RequestLoggerMiddleware(BaseHTTPMiddleware):
    """è®°å½•æ‰€æœ‰APIè¯·æ±‚çš„ä¸­é—´ä»¶"""

    async def dispatch(self, request: Request, call_next):
        # è®°å½•è¯·æ±‚ä¿¡æ¯
        request_id = str(uuid.uuid4())[:8]
        start_time = time.time()

        # è·å–å®¢æˆ·ç«¯ä¿¡æ¯
        client_host = request.client.host if request.client else "unknown"

        # è®°å½•è¯·æ±‚å¼€å§‹
        logger.info(f"")
        logger.info(f"{'='*80}")
        logger.info(f"[{request_id}] ğŸ“¥ æ”¶åˆ°è¯·æ±‚")
        logger.info(f"[{request_id}]   æ–¹æ³•: {request.method}")
        logger.info(f"[{request_id}]   è·¯å¾„: {request.url.path}")
        logger.info(f"[{request_id}]   å®¢æˆ·ç«¯: {client_host}")
        logger.info(f"[{request_id}]   User-Agent: {request.headers.get('user-agent', 'N/A')}")

        # å¦‚æœæ˜¯ POST è¯·æ±‚ï¼Œè®°å½• Content-Type
        if request.method == "POST":
            content_type = request.headers.get('content-type', 'N/A')
            logger.info(f"[{request_id}]   Content-Type: {content_type}")

        logger.info(f"{'='*80}")

        # å¤„ç†è¯·æ±‚
        try:
            response = await call_next(request)

            # è®¡ç®—è€—æ—¶
            process_time = time.time() - start_time

            # è®°å½•å“åº”
            logger.info(f"")
            logger.info(f"{'='*80}")
            logger.info(f"[{request_id}] ğŸ“¤ è¿”å›å“åº”")
            logger.info(f"[{request_id}]   çŠ¶æ€ç : {response.status_code}")
            logger.info(f"[{request_id}]   è€—æ—¶: {process_time:.3f}ç§’")
            logger.info(f"{'='*80}")
            logger.info(f"")

            # æ·»åŠ å“åº”å¤´
            response.headers["X-Request-ID"] = request_id
            response.headers["X-Process-Time"] = f"{process_time:.3f}"

            return response

        except Exception as e:
            # è®°å½•é”™è¯¯
            process_time = time.time() - start_time
            logger.error(f"")
            logger.error(f"{'='*80}")
            logger.error(f"[{request_id}] âŒ è¯·æ±‚å¤„ç†å¤±è´¥")
            logger.error(f"[{request_id}]   é”™è¯¯: {str(e)}")
            logger.error(f"[{request_id}]   è€—æ—¶: {process_time:.3f}ç§’")
            logger.error(f"{'='*80}")
            logger.error(f"", exc_info=True)
            raise


# ============ FastAPI åº”ç”¨ ============

app = FastAPI(
    title="å¤šæ¨¡æ€ RAG API",
    description="æ”¯æŒ PDFã€CADã€å›¾åƒçš„å¤šæ¨¡æ€æ–‡æ¡£æ£€ç´¢ä¸é—®ç­”ç³»ç»Ÿ",
    version="1.0.0"
)

# æ·»åŠ è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
app.add_middleware(RequestLoggerMiddleware)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æœåŠ¡
service = MultimodalRAGService()


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "å¤šæ¨¡æ€ RAG API",
        "version": "1.0.0",
        "status": "running"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }


@app.post("/search", response_model=SearchResponse)
async def search(request: SearchRequest):
    """æœç´¢æ¥å£"""
    try:
        log_request(f"\n{'='*80}")
        log_request(f"ğŸ” APIæ”¶åˆ°æœç´¢è¯·æ±‚")
        log_request(f"  æŸ¥è¯¢: {request.query}")
        log_request(f"  æ¨¡å‹: {request.model}")
        log_request(f"  ç­–ç•¥: {request.strategy}")
        log_request(f"  TopK: {request.topK}")
        print(f"{'='*80}\n")
        sys.stdout.flush()

        result = await service.handle_search(request)

        log_request(f"\n{'='*80}")
        log_request(f"âœ“ APIæœç´¢å®Œæˆï¼Œè¿”å› {result.totalCount} ä¸ªç»“æœ")
        print(f"{'='*80}\n")
        sys.stdout.flush()

        return result
    except Exception as e:
        print(f"\nâŒ æœç´¢å¤±è´¥: {e}\n")
        sys.stdout.flush()
        logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/upload", response_model=UploadResponse)
async def upload(
    file: UploadFile = File(...),
    image_type: Optional[str] = None
):
    """
    æ–‡ä»¶ä¸Šä¼ æ¥å£

    Args:
        file: ä¸Šä¼ çš„æ–‡ä»¶
        image_type: å¯é€‰çš„å›¾ç‰‡ç±»å‹æŒ‡å®š
                   æ”¯æŒ: cad, floor_plan, architecture, technical_doc
    """
    try:
        log_request(f"\n{'='*80}")
        log_request(f"ğŸ“¤ APIæ”¶åˆ°æ–‡ä»¶ä¸Šä¼ è¯·æ±‚")
        log_request(f"  æ–‡ä»¶å: {file.filename}")
        log_request(f"  Content-Type: {file.content_type}")
        if image_type:
            log_request(f"  æŒ‡å®šç±»å‹: {image_type}")
        print(f"{'='*80}\n")
        sys.stdout.flush()

        result = await service.handle_upload(file, image_type)

        log_request(f"\n{'='*80}")
        print(f"{'âœ“' if result.success else 'âŒ'} æ–‡ä»¶ä¸Šä¼ {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
        log_request(f"  æ¶ˆæ¯: {result.message}")
        if result.detectedImageType:
            log_request(f"  æ£€æµ‹ç±»å‹: {result.detectedImageType}")
        print(f"{'='*80}\n")
        sys.stdout.flush()

        return result
    except Exception as e:
        print(f"\nâŒ ä¸Šä¼ å¤±è´¥: {e}\n")
        sys.stdout.flush()
        logger.error(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/question", response_model=FollowUpQuestionResponse)
async def follow_up_question(request: FollowUpQuestionRequest):
    """è¿½é—®æ¥å£"""
    try:
        return await service.handle_follow_up_question(request)
    except Exception as e:
        logger.error(f"âŒ è¿½é—®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ask", response_model=IntelligentQAResponse)
async def intelligent_qa(request: IntelligentQARequest):
    """
    æ™ºèƒ½é—®ç­”æ¥å£ - ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜

    æ”¯æŒä¸‰ç§æŸ¥è¯¢ç±»å‹ï¼š
    1. ç²¾ç¡®æŸ¥è¯¢ï¼šä»å…ƒæ•°æ®ç›´æ¥æå–ç­”æ¡ˆï¼ˆå¦‚ï¼š"æœ‰å‡ ä¸ªå§å®¤ï¼Ÿ"ï¼‰
    2. è¿‡æ»¤æŸ¥è¯¢ï¼šæ™ºèƒ½è¿‡æ»¤ + æ£€ç´¢ï¼ˆå¦‚ï¼š"æ‰¾3ä¸ªå§å®¤çš„æˆ·å‹"ï¼‰
    3. ä¸€èˆ¬æŸ¥è¯¢ï¼šå‘é‡æ£€ç´¢ + LLMç”Ÿæˆç­”æ¡ˆ
    """
    try:
        log_request(f"\n{'='*80}")
        log_request(f"ğŸ¤– APIæ”¶åˆ°æ™ºèƒ½é—®ç­”è¯·æ±‚")
        log_request(f"  é—®é¢˜: {request.question}")
        log_request(f"  TopK: {request.top_k}")
        print(f"{'='*80}\n")
        sys.stdout.flush()

        result = await service.handle_intelligent_qa(request)

        log_request(f"\n{'='*80}")
        log_request(f"âœ“ ç­”æ¡ˆå·²ç”Ÿæˆ")
        log_request(f"  é—®é¢˜ç±»å‹: {result.query_type}")
        log_request(f"  ç½®ä¿¡åº¦: {result.confidence:.2f}")
        log_request(f"  æ¥æºæ•°: {len(result.sources)}")
        print(f"{'='*80}\n")
        sys.stdout.flush()

        return result
    except Exception as e:
        print(f"\nâŒ æ™ºèƒ½é—®ç­”å¤±è´¥: {e}\n")
        sys.stdout.flush()
        logger.error(f"âŒ æ™ºèƒ½é—®ç­”å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/preview/{file_id}")
async def get_preview(file_id: str):
    """è·å–æ–‡æ¡£é¢„è§ˆ"""
    # é¢„è§ˆå’Œç¼©ç•¥å›¾æš‚æ—¶ä¸€æ ·ï¼Œè¿”å›åŸå›¾
    return await get_thumbnail(file_id)


@app.get("/thumbnail/{file_id}")
async def get_thumbnail(file_id: str):
    """è·å–æ–‡æ¡£ç¼©ç•¥å›¾"""
    try:
        # æŸ¥æ‰¾æ–‡ä»¶
        for ext in ['.png', '.jpg', '.jpeg', '.pdf', '.dwg', '.dxf']:
            file_path = service.upload_dir / f"{file_id}{ext}"
            if file_path.exists():
                # å¯¹äºå›¾ç‰‡ï¼Œç›´æ¥è¿”å›åŸå›¾
                if ext in ['.png', '.jpg', '.jpeg']:
                    return FileResponse(file_path, media_type=f"image/{ext[1:]}")
                # å¯¹äºPDFï¼Œè¿”å›ç¼©ç•¥å›¾
                elif ext == '.pdf':
                    thumbnail_path = service.preview_dir / f"{file_id}_thumb.png"
                    if thumbnail_path.exists():
                        return FileResponse(thumbnail_path, media_type="image/png")
                    else:
                        # å¦‚æœç¼©ç•¥å›¾ä¸å­˜åœ¨ï¼Œå°è¯•ç”Ÿæˆ
                        thumb_path = service._generate_pdf_thumbnail(file_path, file_id)
                        if thumb_path and thumb_path.exists():
                            return FileResponse(thumb_path, media_type="image/png")
                        else:
                            raise HTTPException(status_code=500, detail="PDFç¼©ç•¥å›¾ç”Ÿæˆå¤±è´¥")
                else:
                    raise HTTPException(status_code=501, detail="è¯¥æ–‡ä»¶ç±»å‹æš‚ä¸æ”¯æŒç¼©ç•¥å›¾")

        raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {file_id}")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ç¼©ç•¥å›¾å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/download/{document_id}")
async def download_document(document_id: str):
    """ä¸‹è½½æ–‡æ¡£"""
    # TODO: å®ç°æ–‡æ¡£ä¸‹è½½
    raise HTTPException(status_code=501, detail="ä¸‹è½½åŠŸèƒ½æš‚æœªå®ç°")


# ============ å¯åŠ¨æœåŠ¡ ============

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸš€ å¯åŠ¨å¤šæ¨¡æ€ RAG æœåŠ¡")
    print("="*60 + "\n")

    # é…ç½® uvicorn æ—¥å¿—
    log_config = uvicorn.config.LOGGING_CONFIG
    log_config["formatters"]["default"]["fmt"] = "%(message)s"
    log_config["formatters"]["access"]["fmt"] = '%(client_addr)s - "%(request_line)s" %(status_code)s'

    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        log_config=log_config,
        access_log=True
    )
