"""
ç®€åŒ–ç‰ˆå›¾åƒè¯†åˆ«æ¨¡å— - ç¬¬ä¸€æ­¥å®ç°
åŠŸèƒ½ï¼šåŠ è½½å›¾ç‰‡ + VLMè¯†åˆ« + æ ¹æ®ç”¨æˆ·é—®é¢˜å›å¤

æ”¯æŒä¸‰ç§åœºæ™¯ï¼š
1. CADå·¥ç¨‹åˆ¶é€ å›¾çº¸è§£è¯»ï¼ˆç»“æ„ã€å°ºå¯¸ã€å‚æ•°ï¼‰
2. ç ”å‘æ¶æ„å›¾ç†è§£ï¼ˆæ¶æ„ã€æµç¨‹å›¾è¯­ä¹‰ï¼‰
3. å·¥ä¸šæŠ€æœ¯æ¡£æ¡ˆè¯†åˆ«ï¼ˆå·¥è‰ºæ–‡ä»¶ã€è®¾è®¡ç‰ˆæœ¬ï¼‰
"""

import io
import base64
import asyncio
from typing import List, Dict, Any, Optional, Union
from dataclasses import dataclass
from pathlib import Path
from PIL import Image
import aiohttp
import json
import requests
from urllib.parse import urlparse


# ============ é…ç½®éƒ¨åˆ† ============
DEFAULT_MODEL_URL = "https://ai"
DEFAULT_API_KEY = "sk-Y4o8DF6Iq2l8OcieaSnFT"
DEFAULT_MODEL_NAME = "gpt-4o"


@dataclass
class AnalysisResult:
    """å›¾åƒåˆ†æç»“æœ"""
    image_type: str  # cad / architecture / technical_doc
    question: str  # ç”¨æˆ·é—®é¢˜
    answer: str  # VLMå›ç­”
    extracted_info: Dict[str, Any]  # æå–çš„ç»“æ„åŒ–ä¿¡æ¯
    raw_response: str  # åŸå§‹å“åº”
    token_usage: Dict[str, int]  # Tokenä½¿ç”¨ç»Ÿè®¡
    time_cost: float  # è€—æ—¶


class ImageType:
    """å›¾åƒç±»å‹æšä¸¾"""
    CAD = "cad"  # CADå·¥ç¨‹åˆ¶é€ å›¾çº¸
    FLOOR_PLAN = "floor_plan"  # å®¤å†…å¹³é¢å¸ƒç½®å›¾/å»ºç­‘å¹³é¢å›¾
    ARCHITECTURE = "architecture"  # ç ”å‘æ¶æ„å›¾/æµç¨‹å›¾
    TECHNICAL_DOC = "technical_doc"  # å·¥ä¸šæŠ€æœ¯æ¡£æ¡ˆ/å·¥è‰ºæ–‡ä»¶


class SimpleVLMAnalyzer:
    """ç®€åŒ–ç‰ˆVLMå›¾åƒåˆ†æå™¨"""

    # é’ˆå¯¹ä¸åŒå›¾çº¸ç±»å‹çš„æç¤ºè¯æ¨¡æ¿
    PROMPTS = {
        ImageType.CAD: """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„CADå›¾çº¸åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æè¿™å¼ CADå·¥ç¨‹åˆ¶é€ å›¾çº¸ã€‚

**ç”¨æˆ·é—®é¢˜ï¼š**
{question}

**åˆ†æè¦æ±‚ï¼š**
1. **ç»“æ„è¯†åˆ«**ï¼šè¯†åˆ«å›¾çº¸ä¸­çš„ä¸»è¦é›¶éƒ¨ä»¶ç»“æ„ã€ç»„æˆéƒ¨åˆ†
2. **å°ºå¯¸å‚æ•°**ï¼šæå–æ‰€æœ‰å…³é”®å°ºå¯¸æ ‡æ³¨ï¼ˆé•¿åº¦ã€å®½åº¦ã€é«˜åº¦ã€ç›´å¾„ã€è§’åº¦ç­‰ï¼‰
3. **æŠ€æœ¯å‚æ•°**ï¼šè¯†åˆ«å…¬å·®ã€è¡¨é¢ç²—ç³™åº¦ã€ææ–™è¦æ±‚ç­‰æŠ€æœ¯æ ‡æ³¨
4. **æ ‡é¢˜æ ä¿¡æ¯**ï¼šæå–å›¾çº¸ç¼–å·ã€åç§°ã€æ¯”ä¾‹ã€ææ–™ã€è®¾è®¡è€…ç­‰ä¿¡æ¯
5. **è§†å›¾è¯´æ˜**ï¼šè¯´æ˜åŒ…å«å“ªäº›è§†å›¾ï¼ˆä¸»è§†å›¾ã€ä¿¯è§†å›¾ã€ä¾§è§†å›¾ã€å‰–è§†å›¾ç­‰ï¼‰

**å›ç­”æ–¹å¼ï¼š**
- é¦–å…ˆç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
- ç„¶åæä¾›ç›¸å…³çš„è¯¦ç»†æŠ€æœ¯ä¿¡æ¯
- å¦‚æœå›¾çº¸ä¸­æœ‰å…³é”®æ•°æ®ï¼Œè¯·åˆ—å‡ºæ¥

**è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š**
{{
    "answer": "ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„å†…å®¹",
    "extracted_info": {{
        "drawing_title": "å›¾çº¸åç§°",
        "drawing_number": "å›¾çº¸ç¼–å·",
        "scale": "æ¯”ä¾‹",
        "material": "ææ–™",
        "main_dimensions": {{"é•¿": "xxx", "å®½": "xxx", "é«˜": "xxx"}},
        "key_features": ["ç‰¹å¾1", "ç‰¹å¾2"],
        "technical_requirements": ["è¦æ±‚1", "è¦æ±‚2"],
        "views": ["ä¸»è§†å›¾", "ä¿¯è§†å›¾"]
    }}
}}""",

        ImageType.FLOOR_PLAN: """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å»ºç­‘/å®¤å†…å¹³é¢å›¾åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æè¿™å¼ å®¤å†…å¹³é¢å¸ƒç½®å›¾ã€‚

**ç”¨æˆ·é—®é¢˜ï¼š**
{question}

**é‡è¦è¯´æ˜ï¼š**
- è¿™æ˜¯ä¸€å¼ å®¤å†…å¹³é¢å¸ƒç½®å›¾ï¼ŒåŒ…å«æˆ¿é—´ã€å°ºå¯¸æ ‡æ³¨ã€å®¶å…·å¸ƒç½®ã€åŠ¨çº¿ç­‰ä¿¡æ¯
- å›¾ä¸­å°ºå¯¸å•ä½é€šå¸¸ä¸ºæ¯«ç±³(mm)æˆ–ç±³(m)ï¼Œè¯·æ ¹æ®æ•°å€¼å¤§å°æ¨æ–­
- è¯·ä»”ç»†è¯†åˆ«æ‰€æœ‰å¯è§çš„æˆ¿é—´ã€æ ‡æ³¨ã€ç¬¦å·å’Œç©ºé—´å…³ç³»

**åˆ†æç»´åº¦ï¼ˆæ ¹æ®ç”¨æˆ·é—®é¢˜é€‰æ‹©æ€§å›ç­”ï¼‰ï¼š**

1. **æˆ¿é—´/åŠŸèƒ½åŒºè¯†åˆ«**ï¼š
   - è¯†åˆ«æ‰€æœ‰æˆ¿é—´åç§°ï¼ˆå®¢å…ã€å§å®¤ã€å¨æˆ¿ã€å«ç”Ÿé—´ã€é˜³å°ç­‰ï¼‰
   - æ ‡æ³¨æ¯ä¸ªæˆ¿é—´çš„ä½ç½®ï¼ˆå·¦ä¸Š/å³ä¸‹/ä¸­å¤®ç­‰æ–¹ä½ï¼‰
   - è¯†åˆ«ç‰¹æ®ŠåŠŸèƒ½åŒºï¼ˆå‚¨è—å®¤ã€ç„å…³ã€è¡£å¸½é—´ç­‰ï¼‰

2. **å°ºå¯¸ä¸é¢ç§¯**ï¼š
   - æå–å›¾ä¸­æ‰€æœ‰å¯è§å°ºå¯¸æ ‡æ³¨
   - æ¨æ–­å•ä½å¹¶ç»Ÿä¸€æ¢ç®—ä¸ºç±³(m)
   - è®¡ç®—æˆ¿é—´çš„é•¿ã€å®½ã€é¢ç§¯
   - æ ‡æ³¨æ•´ä½“å¹³é¢å¤–å¢™å°ºå¯¸

3. **ç¬¦å·ä¸æ ‡æ³¨**ï¼š
   - è§£é‡Šç¬¦å·å«ä¹‰ï¼ˆè™šçº¿ã€ç®­å¤´ã€çº¢ç‚¹/çº¢çº¿ã€è½´çº¿ç­‰ï¼‰
   - è¯†åˆ«æ–‡å­—æ ‡æ³¨ï¼ˆæˆ¿é—´ç¼–å·ã€é¢ç§¯ã€å¤‡æ³¨ï¼‰
   - è¯´æ˜å¢™ä½“ç±»å‹ã€é—¨çª—ä½ç½®å’Œå¼€å¯æ–¹å‘

4. **å®¶å…·å¸ƒå±€**ï¼š
   - åˆ—å‡ºæ‰€æœ‰å¯è§å®¶å…·åŠå…¶ä½ç½®
   - åˆ¤æ–­ç©ºé—´åˆ©ç”¨ç‡ï¼ˆæ‹¥æŒ¤/é€‚ä¸­/ç©ºæ—·ï¼‰
   - è¯†åˆ«å®¶å…·å°ºå¯¸

5. **åŠ¨çº¿ä¸è¿é€šæ€§**ï¼š
   - æ ‡å‡ºä¸»å…¥å£ã€æ¬¡å…¥å£ä½ç½®
   - æè¿°ä¸»è¦åŠ¨çº¿è·¯å¾„ï¼ˆå¦‚ï¼š"å…¥å£â†’ç„å…³â†’å®¢å…â†’..."ï¼‰
   - åˆ—å‡ºæˆ¿é—´è¿é€šå…³ç³»ï¼ˆå“ªäº›æˆ¿é—´ç›¸è¿ï¼‰
   - åˆ¤æ–­å¸ƒå±€ç±»å‹ï¼ˆå¼€æ”¾å¼/åˆ†éš”å¼ï¼‰

6. **è®¾è®¡è¯„ä¼°**ï¼ˆå¦‚æœé—®é¢˜æ¶‰åŠï¼‰ï¼š
   - åŠ¨çº¿åˆç†æ€§ã€æ˜¯å¦æœ‰ç»•è¡Œæˆ–æ­»è§’
   - é‡‡å…‰/æœå‘åˆ†æ
   - ç©ºé—´ä¼˜åŒ–å»ºè®®

**å›ç­”æ–¹å¼ï¼š**
- é¦–å…ˆç›´æ¥ã€ç®€æ´åœ°å›ç­”ç”¨æˆ·çš„å…·ä½“é—®é¢˜
- ç„¶åæä¾›ç›¸å…³çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœç”¨æˆ·é—®æŸä¸ªæˆ¿é—´ï¼Œé‡ç‚¹æè¿°è¯¥æˆ¿é—´ï¼‰
- å¦‚æœç”¨æˆ·é—®æ•´ä½“å¸ƒå±€ï¼Œæä¾›å…¨å±€åˆ†æ
- å¦‚æœæ¶‰åŠå°ºå¯¸è®¡ç®—ï¼Œè¯·è¯´æ˜æ¨ç†è¿‡ç¨‹ï¼ˆå¦‚ï¼š"æ ‡æ³¨22720mm = 22.72m"ï¼‰

**è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š**
{{
    "answer": "ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒå†…å®¹ï¼ˆç®€æ´æ˜äº†ï¼‰",
    "extracted_info": {{
        "total_dimensions": {{
            "length": 22.72,
            "width": 12.5,
            "unit": "m",
            "total_area": 284.0
        }},
        "rooms": [
            {{
                "name": "å®¢å…",
                "position": "ä¸­å¤®åå³",
                "dimensions": {{"length": 5.79, "width": 4.2, "area": 24.3, "unit": "m"}},
                "furniture": ["æ²™å‘", "èŒ¶å‡ "],
                "connected_to": ["é¤å…", "å§å®¤1"],
                "windows": 2,
                "doors": 1
            }}
        ],
        "annotations": [
            {{"type": "dimension", "value": "22720", "parsed_value": 22.72, "unit": "m", "description": "å¤–å¢™æ€»é•¿"}}
        ],
        "symbols": [
            {{"type": "door", "count": 5, "positions": ["å®¢å…-é¤å…", "å§å®¤1å…¥å£"]}}
        ],
        "circulation": {{
            "main_entrance": "åº•éƒ¨ä¸­å¤®",
            "main_path": "ä¸»å…¥å£ â†’ ç„å…³ â†’ å®¢å… â†’ é¤å…",
            "layout_type": "å¼€æ”¾å¼å®¢é¤å…"
        }},
        "design_notes": ["ä¸»å§å¸¦ç‹¬ç«‹å«ç”Ÿé—´", "åŠ¨çº¿æµç•…"]
    }}
}}

**æ³¨æ„äº‹é¡¹ï¼š**
- å¦‚æœæ ‡æ³¨ä¸æ¸…æ™°ï¼Œæ ‡æ³¨ä¸º"ä¸å¯è¯»"æˆ–ç»™å‡ºä¼°ç®—å€¼å¹¶è¯´æ˜
- ä¼˜å…ˆå›ç­”ç”¨æˆ·çš„å…·ä½“é—®é¢˜ï¼Œä¸è¦ç½—åˆ—æ‰€æœ‰ä¿¡æ¯
- å¦‚æœç”¨æˆ·é—®"æœ‰å‡ ä¸ªå§å®¤"ï¼Œå°±é‡ç‚¹å›ç­”å§å®¤æ•°é‡å’Œä½ç½®
- å¦‚æœç”¨æˆ·é—®"å®¢å…é¢ç§¯"ï¼Œå°±é‡ç‚¹å›ç­”å®¢å…çš„å°ºå¯¸å’Œé¢ç§¯
- ä¿æŒç­”æ¡ˆç®€æ´ã€é’ˆå¯¹æ€§å¼º""",

        ImageType.ARCHITECTURE: """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç³»ç»Ÿæ¶æ„å’Œæµç¨‹å›¾åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æè¿™å¼ æ¶æ„å›¾/æµç¨‹å›¾ã€‚

**ç”¨æˆ·é—®é¢˜ï¼š**
{question}

**åˆ†æè¦æ±‚ï¼š**
1. **æ•´ä½“æ¶æ„**ï¼šè¯†åˆ«ç³»ç»Ÿçš„æ•´ä½“ç»“æ„å’Œåˆ†å±‚
2. **ç»„ä»¶è¯†åˆ«**ï¼šè¯†åˆ«å›¾ä¸­çš„æ‰€æœ‰æ¨¡å—ã€ç»„ä»¶ã€æœåŠ¡
3. **å…³ç³»åˆ†æ**ï¼šåˆ†æç»„ä»¶ä¹‹é—´çš„è¿æ¥å…³ç³»ã€æ•°æ®æµå‘ã€è°ƒç”¨å…³ç³»
4. **æµç¨‹ç†è§£**ï¼šå¦‚æœæ˜¯æµç¨‹å›¾ï¼Œè¯´æ˜ä¸šåŠ¡æµç¨‹çš„æ­¥éª¤å’Œé€»è¾‘
5. **æŠ€æœ¯æ ˆ**ï¼šè¯†åˆ«ä½¿ç”¨çš„æŠ€æœ¯ã€åè®®ã€æ¥å£ç±»å‹
6. **å…³é”®èŠ‚ç‚¹**ï¼šæ ‡æ³¨å…³é”®çš„å†³ç­–ç‚¹ã€ç½‘å…³ã€æ•°æ®åº“ç­‰

**å›ç­”æ–¹å¼ï¼š**
- é¦–å…ˆç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
- ç„¶åæä¾›æ¶æ„/æµç¨‹çš„æ•´ä½“è¯´æ˜
- åˆ—å‡ºå…³é”®ç»„ä»¶å’Œå®ƒä»¬çš„ä½œç”¨

**è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š**
{{
    "answer": "ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„å†…å®¹",
    "extracted_info": {{
        "diagram_type": "æ¶æ„å›¾/æµç¨‹å›¾/æ—¶åºå›¾ç­‰",
        "main_components": ["ç»„ä»¶1", "ç»„ä»¶2"],
        "layers": ["å±‚çº§1", "å±‚çº§2"],
        "data_flow": ["æµå‘æè¿°1", "æµå‘æè¿°2"],
        "key_technologies": ["æŠ€æœ¯1", "æŠ€æœ¯2"],
        "process_steps": ["æ­¥éª¤1", "æ­¥éª¤2"]
    }}
}}""",

        ImageType.TECHNICAL_DOC: """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å·¥ä¸šæŠ€æœ¯æ–‡æ¡£åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æè¿™ä»½å·¥è‰ºæ–‡ä»¶/æŠ€æœ¯æ¡£æ¡ˆã€‚

**ç”¨æˆ·é—®é¢˜ï¼š**
{question}

**åˆ†æè¦æ±‚ï¼š**
1. **æ–‡æ¡£ç±»å‹**ï¼šè¯†åˆ«æ˜¯å·¥è‰ºå¡ç‰‡ã€æ£€éªŒæŠ¥å‘Šã€è®¾è®¡å˜æ›´å•ç­‰
2. **æ ¸å¿ƒå†…å®¹**ï¼šæå–æ–‡æ¡£çš„ä¸»è¦æŠ€æœ¯å†…å®¹
3. **å‚æ•°æ•°æ®**ï¼šæå–æ‰€æœ‰å…³é”®å‚æ•°ã€æ•°å€¼ã€è§„æ ¼
4. **è¡¨æ ¼ä¿¡æ¯**ï¼šå¦‚æœæœ‰è¡¨æ ¼ï¼Œæå–è¡¨æ ¼ä¸­çš„æ•°æ®
5. **ç‰ˆæœ¬ä¿¡æ¯**ï¼šè¯†åˆ«ç‰ˆæœ¬å·ã€ä¿®è®¢è®°å½•ã€å®¡æ‰¹ä¿¡æ¯
6. **å·¥è‰ºæµç¨‹**ï¼šå¦‚æœæ˜¯å·¥è‰ºæ–‡ä»¶ï¼Œè¯´æ˜åŠ å·¥æ­¥éª¤å’Œå·¥è‰ºè¦æ±‚

**å›ç­”æ–¹å¼ï¼š**
- é¦–å…ˆç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
- ç„¶åæä¾›æ–‡æ¡£çš„å…³é”®ä¿¡æ¯
- å¦‚æœæœ‰è¡¨æ ¼æ•°æ®æˆ–å‚æ•°åˆ—è¡¨ï¼Œå®Œæ•´åˆ—å‡º

**è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š**
{{
    "answer": "ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„å†…å®¹",
    "extracted_info": {{
        "document_type": "æ–‡æ¡£ç±»å‹",
        "document_number": "æ–‡æ¡£ç¼–å·",
        "version": "ç‰ˆæœ¬å·",
        "revision_date": "ä¿®è®¢æ—¥æœŸ",
        "key_parameters": {{"å‚æ•°å": "å‚æ•°å€¼"}},
        "process_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
        "inspection_items": ["æ£€éªŒé¡¹1", "æ£€éªŒé¡¹2"],
        "tables_data": []
    }}
}}"""
    }

    def __init__(
        self,
        model_url: str = DEFAULT_MODEL_URL,
        api_key: str = DEFAULT_API_KEY,
        model_name: str = DEFAULT_MODEL_NAME
    ):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.model_url = model_url
        self.api_key = api_key
        self.model_name = model_name

        # æ£€æµ‹APIç±»å‹
        self.api_type = self._detect_api_type()
        print(f"âœ“ åˆå§‹åŒ–VLMåˆ†æå™¨: {self.api_type} - {self.model_name}")

        # å¦‚æœä½¿ç”¨OpenAI SDKï¼Œåˆå§‹åŒ–å®¢æˆ·ç«¯
        if self.api_type == "openai_sdk":
            from openai import AsyncOpenAI
            base_url = model_url.replace("/chat/completions", "") if "/chat/completions" in model_url else model_url
            self.openai_client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        else:
            self.openai_client = None

    def _detect_api_type(self) -> str:
        """æ£€æµ‹APIç±»å‹"""
        url_lower = self.model_url.lower()

        if "dashscope" in url_lower or "aliyun" in url_lower:
            return "qwen"
        elif "anthropic" in url_lower or "claude" in url_lower:
            return "claude"
        elif "openai.com" in url_lower or "gpt" in self.model_name.lower():
            return "openai_sdk"
        else:
            return "openai_sdk"  # é»˜è®¤ä½¿ç”¨OpenAIæ ¼å¼

    def _get_request_url(self) -> str:
        """è·å–å®Œæ•´çš„è¯·æ±‚URL"""
        url = self.model_url
        if "/chat/completions" not in url and url.endswith("/v1"):
            return url + "/chat/completions"
        return url

    def load_image(self, image_source: Union[str, Path, Image.Image]) -> Image.Image:
        """
        åŠ è½½å›¾ç‰‡ï¼ˆæ”¯æŒæœ¬åœ°æ–‡ä»¶ã€URLã€PIL Imageå¯¹è±¡ï¼‰

        Args:
            image_source: å›¾ç‰‡æ¥æºï¼ˆæœ¬åœ°è·¯å¾„ã€URLæˆ–PIL Imageå¯¹è±¡ï¼‰

        Returns:
            PIL Imageå¯¹è±¡
        """
        # å¦‚æœå·²ç»æ˜¯PIL Imageå¯¹è±¡
        if isinstance(image_source, Image.Image):
            print(f"âœ“ æ¥æ”¶åˆ°PIL Imageå¯¹è±¡: {image_source.size}")
            return image_source

        image_source = str(image_source)

        # å¦‚æœæ˜¯URL
        if image_source.startswith(('http://', 'https://')):
            print(f"â¬‡ æ­£åœ¨ä»URLä¸‹è½½å›¾ç‰‡: {image_source}")
            response = requests.get(image_source, timeout=30)
            response.raise_for_status()
            image = Image.open(io.BytesIO(response.content))
            print(f"âœ“ å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {image.size}")
            return image

        # å¦åˆ™è§†ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
        image_path = Path(image_source)
        if not image_path.exists():
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")

        print(f"ğŸ“ æ­£åœ¨åŠ è½½æœ¬åœ°å›¾ç‰‡: {image_path.name}")
        image = Image.open(image_path)
        print(f"âœ“ å›¾ç‰‡åŠ è½½æˆåŠŸ: {image.size}")
        return image

    def image_to_base64(self, image: Image.Image, max_size: int = 2000) -> str:
        """å°†PIL Imageè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        # å‹ç¼©å¤§å›¾ç‰‡
        if image.width > max_size or image.height > max_size:
            image = image.copy()  # é¿å…ä¿®æ”¹åŸå›¾
            image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
            print(f"  å›¾ç‰‡å·²å‹ç¼©åˆ°: {image.size}")

        buffer = io.BytesIO()
        if image.mode == 'RGBA':
            image = image.convert('RGB')
        image.save(buffer, format='JPEG', quality=85)
        buffer.seek(0)
        return base64.b64encode(buffer.read()).decode('utf-8')

    async def analyze_image(
        self,
        image_source: Union[str, Path, Image.Image],
        question: str,
        image_type: str = ImageType.CAD
    ) -> AnalysisResult:
        """
        åˆ†æå›¾åƒå¹¶å›ç­”é—®é¢˜

        Args:
            image_source: å›¾ç‰‡æ¥æºï¼ˆæœ¬åœ°è·¯å¾„ã€URLæˆ–PIL Imageå¯¹è±¡ï¼‰
            question: ç”¨æˆ·é—®é¢˜
            image_type: å›¾åƒç±»å‹ (cad / architecture / technical_doc)

        Returns:
            AnalysisResultå¯¹è±¡
        """
        import time
        start_time = time.time()

        print("\n" + "="*60)
        print(f"ğŸ” å¼€å§‹å›¾åƒåˆ†æ")
        print(f"   ç±»å‹: {image_type}")
        print(f"   é—®é¢˜: {question}")
        print("="*60)

        # 1. åŠ è½½å›¾ç‰‡
        image = self.load_image(image_source)

        # 2. è½¬æ¢ä¸ºbase64
        print("ğŸ”„ æ­£åœ¨å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64...")
        image_base64 = self.image_to_base64(image)
        print(f"âœ“ è½¬æ¢å®Œæˆ: {len(image_base64) / 1024:.1f} KB")

        # 3. æ„å»ºæç¤ºè¯
        if image_type not in self.PROMPTS:
            raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒç±»å‹: {image_type}ï¼Œæ”¯æŒçš„ç±»å‹: {list(self.PROMPTS.keys())}")

        prompt = self.PROMPTS[image_type].format(question=question)

        # 4. è°ƒç”¨VLM API
        print(f"ğŸš€ æ­£åœ¨è°ƒç”¨VLMæ¨¡å‹: {self.model_name}")
        response_data = await self._call_vlm_api(image_base64, prompt)

        # 5. è§£æå“åº”
        answer = response_data.get('answer', '')
        extracted_info = response_data.get('extracted_info', {})
        raw_response = response_data.get('raw_response', '')
        token_usage = response_data.get('token_usage', {})

        time_cost = time.time() - start_time

        print("\n" + "="*60)
        print("âœ… åˆ†æå®Œæˆ")
        print(f"   è€—æ—¶: {time_cost:.2f}ç§’")
        print(f"   Token: {token_usage.get('total_tokens', 0)}")
        print("="*60)

        return AnalysisResult(
            image_type=image_type,
            question=question,
            answer=answer,
            extracted_info=extracted_info,
            raw_response=raw_response,
            token_usage=token_usage,
            time_cost=time_cost
        )

    async def _call_vlm_api(self, image_base64: str, prompt: str) -> Dict[str, Any]:
        """è°ƒç”¨VLM APIï¼ˆæ ¹æ®APIç±»å‹è‡ªåŠ¨é€‰æ‹©è°ƒç”¨æ–¹å¼ï¼‰"""
        if self.api_type == "openai_sdk":
            return await self._call_openai_api(image_base64, prompt)
        elif self.api_type == "qwen":
            return await self._call_qwen_api(image_base64, prompt)
        elif self.api_type == "claude":
            return await self._call_claude_api(image_base64, prompt)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„APIç±»å‹: {self.api_type}")

    async def _call_openai_api(self, image_base64: str, prompt: str) -> Dict[str, Any]:
        """è°ƒç”¨OpenAIæ ¼å¼çš„API"""
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å·¥ä¸šå›¾çº¸å’ŒæŠ€æœ¯æ–‡æ¡£åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æå›¾åƒå¹¶æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›ç»“æœã€‚"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ]

        try:
            response = await self.openai_client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=4096,
                temperature=0.1,
                response_format={"type": "json_object"}
            )

            content = response.choices[0].message.content

            # Tokenç»Ÿè®¡
            token_usage = {}
            if response.usage:
                token_usage = {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
                print(f"  Tokenä½¿ç”¨: è¾“å…¥={token_usage['prompt_tokens']}, "
                      f"è¾“å‡º={token_usage['completion_tokens']}, "
                      f"æ€»è®¡={token_usage['total_tokens']}")

            # è§£æJSONå“åº”
            parsed = self._parse_json_response(content)

            return {
                'answer': parsed.get('answer', ''),
                'extracted_info': parsed.get('extracted_info', {}),
                'raw_response': content,
                'token_usage': token_usage
            }

        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
            raise

    async def _call_qwen_api(self, image_base64: str, prompt: str) -> Dict[str, Any]:
        """è°ƒç”¨é€šä¹‰åƒé—®API"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        payload = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å·¥ä¸šå›¾çº¸å’ŒæŠ€æœ¯æ–‡æ¡£åˆ†æä¸“å®¶ã€‚"
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ],
            "max_tokens": 4096,
            "temperature": 0.1
        }

        request_url = self._get_request_url()

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    request_url,
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=300)
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"APIé”™è¯¯ {response.status}: {error_text[:500]}")

                    result = await response.json()
                    content = result['choices'][0]['message']['content']

                    # Tokenç»Ÿè®¡
                    token_usage = {}
                    if 'usage' in result:
                        usage = result['usage']
                        token_usage = {
                            "prompt_tokens": usage.get('prompt_tokens', 0),
                            "completion_tokens": usage.get('completion_tokens', 0),
                            "total_tokens": usage.get('total_tokens', 0)
                        }

                    parsed = self._parse_json_response(content)

                    return {
                        'answer': parsed.get('answer', ''),
                        'extracted_info': parsed.get('extracted_info', {}),
                        'raw_response': content,
                        'token_usage': token_usage
                    }
        except Exception as e:
            print(f"âŒ é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: {e}")
            raise

    async def _call_claude_api(self, image_base64: str, prompt: str) -> Dict[str, Any]:
        """è°ƒç”¨Claude API"""
        headers = {
            "Content-Type": "application/json",
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01"
        }

        payload = {
            "model": self.model_name,
            "max_tokens": 4096,
            "temperature": 0.1,
            "system": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å·¥ä¸šå›¾çº¸å’ŒæŠ€æœ¯æ–‡æ¡£åˆ†æä¸“å®¶ã€‚",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": image_base64
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ]
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    self.model_url,
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=300)
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"APIé”™è¯¯ {response.status}: {error_text[:500]}")

                    result = await response.json()
                    content = result['content'][0]['text']

                    # Tokenç»Ÿè®¡
                    token_usage = {}
                    if 'usage' in result:
                        usage = result['usage']
                        token_usage = {
                            "prompt_tokens": usage.get('input_tokens', 0),
                            "completion_tokens": usage.get('output_tokens', 0),
                            "total_tokens": usage.get('input_tokens', 0) + usage.get('output_tokens', 0)
                        }

                    parsed = self._parse_json_response(content)

                    return {
                        'answer': parsed.get('answer', ''),
                        'extracted_info': parsed.get('extracted_info', {}),
                        'raw_response': content,
                        'token_usage': token_usage
                    }
        except Exception as e:
            print(f"âŒ Claude APIè°ƒç”¨å¤±è´¥: {e}")
            raise

    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """è§£æJSONå“åº”"""
        try:
            # æ¸…ç†markdownä»£ç å—æ ‡è®°
            content = content.strip()
            if content.startswith('```json'):
                content = content[7:]
            elif content.startswith('```'):
                content = content[3:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()

            # å°è¯•æå–JSONéƒ¨åˆ†
            first_brace = content.find('{')
            last_brace = content.rfind('}')
            if first_brace != -1 and last_brace != -1:
                content = content[first_brace:last_brace + 1]

            return json.loads(content)
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹: {e}")
            return {
                'answer': content,
                'extracted_info': {}
            }

    def print_result(self, result: AnalysisResult):
        """ç¾åŒ–æ‰“å°åˆ†æç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†æç»“æœ")
        print("="*60)
        print(f"\nã€å›¾åƒç±»å‹ã€‘ {result.image_type}")
        print(f"\nã€ç”¨æˆ·é—®é¢˜ã€‘ {result.question}")
        print(f"\nã€å›ç­”ã€‘\n{result.answer}")

        if result.extracted_info:
            print(f"\nã€æå–çš„ç»“æ„åŒ–ä¿¡æ¯ã€‘")
            print(json.dumps(result.extracted_info, ensure_ascii=False, indent=2))

        print(f"\nã€ç»Ÿè®¡ä¿¡æ¯ã€‘")
        print(f"  è€—æ—¶: {result.time_cost:.2f}ç§’")
        print(f"  Token: {result.token_usage.get('total_tokens', 0)}")
        print("="*60 + "\n")


# ============ ä¾¿æ·å‡½æ•° ============

async def analyze_cad_drawing(
    image_source: Union[str, Path, Image.Image],
    question: str,
    model_url: str = DEFAULT_MODEL_URL,
    api_key: str = DEFAULT_API_KEY,
    model_name: str = DEFAULT_MODEL_NAME
) -> AnalysisResult:
    """åˆ†æCADå·¥ç¨‹åˆ¶é€ å›¾çº¸"""
    analyzer = SimpleVLMAnalyzer(model_url, api_key, model_name)
    return await analyzer.analyze_image(image_source, question, ImageType.CAD)


async def analyze_architecture_diagram(
    image_source: Union[str, Path, Image.Image],
    question: str,
    model_url: str = DEFAULT_MODEL_URL,
    api_key: str = DEFAULT_API_KEY,
    model_name: str = DEFAULT_MODEL_NAME
) -> AnalysisResult:
    """åˆ†æç ”å‘æ¶æ„å›¾/æµç¨‹å›¾"""
    analyzer = SimpleVLMAnalyzer(model_url, api_key, model_name)
    return await analyzer.analyze_image(image_source, question, ImageType.ARCHITECTURE)


async def analyze_technical_document(
    image_source: Union[str, Path, Image.Image],
    question: str,
    model_url: str = DEFAULT_MODEL_URL,
    api_key: str = DEFAULT_API_KEY,
    model_name: str = DEFAULT_MODEL_NAME
) -> AnalysisResult:
    """åˆ†æå·¥ä¸šæŠ€æœ¯æ¡£æ¡ˆ/å·¥è‰ºæ–‡ä»¶"""
    analyzer = SimpleVLMAnalyzer(model_url, api_key, model_name)
    return await analyzer.analyze_image(image_source, question, ImageType.TECHNICAL_DOC)


async def analyze_floor_plan(
    image_source: Union[str, Path, Image.Image],
    question: str,
    model_url: str = DEFAULT_MODEL_URL,
    api_key: str = DEFAULT_API_KEY,
    model_name: str = DEFAULT_MODEL_NAME
) -> AnalysisResult:
    """åˆ†æå®¤å†…å¹³é¢å¸ƒç½®å›¾/å»ºç­‘å¹³é¢å›¾"""
    analyzer = SimpleVLMAnalyzer(model_url, api_key, model_name)
    return await analyzer.analyze_image(image_source, question, ImageType.FLOOR_PLAN)
