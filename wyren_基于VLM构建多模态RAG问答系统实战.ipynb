{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26974874",
   "metadata": {},
   "source": [
    "- **案例功能介绍**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe1af0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;核心功能一：支持在线上传并自动解析多模态PDF及CAD、工程图纸和复杂架构原型图；\n",
    "\n",
    "<center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151408689.png\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c7460",
   "metadata": {},
   "source": [
    "<center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151456627.png\" style=\"zoom:60%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfb98e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;核心功能二：通过自然语言问答，直接检索图片原型及文档原件，并支持溯源和在线预览，实现“以文搜图”、“以图搜图”；\n",
    "<center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151407213.png\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568df2d7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;核心功能三：支持实时上传多模态PDF及CAD、工程图纸和复杂架构原型图，并直接对文件内容进行提问，实现“以文搜文”；\n",
    "\n",
    "<center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151407214.png\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01c9ce",
   "metadata": {},
   "source": [
    "# 多模态RAG系统架构设计与实现\n",
    "&emsp;&emsp;在了解了多模态RAG的核心概念和实现路线后，接下来我们先通过一个实战项目，为大家展示如何从零开始构建一个完整的多模态RAG系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4f406",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们就深入探索如何构建一个<font color=red>基于多模态RAG的CAD图纸智能问答链路</font>。相信大家在工业制造、建筑设计等领域中，都会遇到大量的技术图纸需要管理和查询。传统的方式是打开图纸逐个查看，效率低下且容易遗漏关键信息。\n",
    "\n",
    "&emsp;&emsp;接下来我们就从零开始，逐步实现一个能够\"读懂\"CAD图纸、自动提取关键信息、并智能回答用户问题的系统，其核心实现思路如下：\n",
    "\n",
    "```json\n",
    "    第一步：接入VLM模型\n",
    "                ↓\n",
    "    第二步：解析本地CAD图片\n",
    "                ↓\n",
    "    第三步：提取结构化元数据\n",
    "                ↓\n",
    "    第四步：存入向量数据库\n",
    "                ↓\n",
    "    第五步：智能问答（直接问答 + 图像检索）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd614e4",
   "metadata": {},
   "source": [
    "- **处理图片示例**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de12184",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151445328.png\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d2ee9",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151445329.png\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148dbbf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这套系统可以直接应用于：\n",
    "- **房地产销售**：快速回答客户关于户型的问题（\"有几个卧室？\"、\"主卧面积多大？\"）\n",
    "- **室内设计**：分析户型优缺点，提供设计建议\n",
    "- **智能选房**：根据用户需求（如\"3室2厅，面积100平以上\"）自动筛选户型\n",
    "- **户型对比**：智能对比多个户型的优劣\n",
    "\n",
    "&emsp;&emsp;同时，只要针对性的修改提示词，即可快速迁移到其他的图像分析场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c559a6",
   "metadata": {},
   "source": [
    "## 5.1 环境准备与依赖安装\n",
    "\n",
    "&emsp;&emsp;首先，我们需要安装必要的Python包。这个系统的核心依赖包括：\n",
    "- `openai`：用于调用多模态大模型API\n",
    "- `chromadb`：向量数据库，用于存储和检索\n",
    "- `langchain`：RAG框架的核心组件\n",
    "- `Pillow`：图像处理库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b496676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖（如果需要）\n",
    "# !pip install openai chromadb langchain langchain-community langchain-openai Pillow python-dotenv -q\n",
    "\n",
    "# 导入必要的库\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from PIL import Image\n",
    "from dataclasses import dataclass\n",
    "import sys\n",
    "# 添加项目路径（使用绝对路径）\n",
    "project_root = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "backend_path = project_root / \"backend\"\n",
    "if str(backend_path) not in sys.path:\n",
    "    sys.path.insert(0, str(backend_path))\n",
    "\n",
    "# OpenAI SDK\n",
    "from openai import OpenAI\n",
    "\n",
    "# LangChain 组件\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from qwen_embeddings import QwenEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad0239",
   "metadata": {},
   "source": [
    "&emsp;&emsp;上述代码中，导入了构建多模态RAG系统所需的所有核心库：\n",
    "\n",
    "- **`openai`**：提供了与 `gpt-4o` 等视觉语言模型交互的接口\n",
    "- **`chromadb` 相关**：通过 `langchain_community.vectorstores.Chroma` 实现向量存储\n",
    "- **`HuggingFaceEmbeddings`**：用于将文本转换为向量表示\n",
    "- **`PIL.Image`**：处理图像文件的加载和转换\n",
    "\n",
    "&emsp;&emsp;至此，我们的环境已经准备完毕，接下来就开始真正的系统构建。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc8914",
   "metadata": {},
   "source": [
    "## 5.2 接入视觉语言模型（VLM）\n",
    "\n",
    "&emsp;&emsp;多模态RAG的核心能力来自于<font color=red>视觉语言模型（Vision-Language Model, VLM）</font>。这类模型能够同时理解图像和文本，对于CAD图纸这种技术图像来说，VLM可以识别其中的结构、尺寸标注、技术参数等关键信息。\n",
    "\n",
    "&emsp;&emsp;本课程中，我们使用 `gpt-4o` 作为VLM模型。首先，我们需要配置API密钥和模型接入点。需要配置三个关键参数：\n",
    "\n",
    "- **`API_KEY`**：你的OpenAI API密钥（或兼容的API服务密钥）\n",
    "- **`BASE_URL`**：API服务的基础URL\n",
    "- **`MODEL_NAME`**：使用的模型名称（这里是 `gpt-4o`）\n",
    "\n",
    "> &emsp;**提示**：如果你使用的是OpenAI官方API，`BASE_URL` 设置为 `https://api.openai.com/v1` 即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0fda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# ========== VLM 模型配置 ==========\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "vlm_client = OpenAI(\n",
    "    # api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    # base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3814ebc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这段代码创建了一个 `OpenAI` 客户端实例，这是我们与视觉语言模型交互的桥梁。通过这个客户端，我们后续可以发送图像和问题给模型，并接收模型的分析结果。\n",
    "\n",
    "&emsp;&emsp;接下来，我们需要构建一个<font color=red>CAD图纸分析器</font>，它能够将图像转换为模型可以理解的格式，并调用VLM进行智能分析。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db02508",
   "metadata": {},
   "source": [
    "## 5.3  **构建CAD图纸分析器**\n",
    "\n",
    "&emsp;&emsp;多模态RAG的核心能力来自于<font color=red>视觉语言模型（VLM）</font>。对于室内平面图来说，VLM需要能够识别：\n",
    "- 房间布局和功能区划分\n",
    "- 尺寸标注和面积计算  \n",
    "- 门窗位置和开启方向\n",
    "- 家具布置和空间利用\n",
    "- 动线设计和连通关系\n",
    "\n",
    "&emsp;&emsp;在实际应用中，针对不同类型的图纸（CAD、平面图、架构图等），我们需要设计不同的提示词模板，以获得最佳的分析效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0c3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AnalysisResult:\n",
    "    \"\"\"图像分析结果数据类\"\"\"\n",
    "    answer: str  # VLM的回答\n",
    "    extracted_info: Dict[str, Any]  # 提取的结构化信息\n",
    "    raw_response: str  # 原始响应内容\n",
    "\n",
    "\n",
    "class FloorPlanAnalyzer:\n",
    "    \"\"\"室内平面图分析器\"\"\"\n",
    "    \n",
    "    # 平面图专业提示词模板\n",
    "    FLOOR_PLAN_PROMPT = \"\"\"你是一位专业的建筑/室内平面图分析专家。请仔细分析这张室内平面布置图。\n",
    "\n",
    "**用户问题：**\n",
    "{question}\n",
    "\n",
    "**重要说明：**\n",
    "- 这是一张室内平面布置图，包含房间、尺寸标注、家具布置、动线等信息\n",
    "- 图中尺寸单位通常为毫米(mm)或米(m)，请根据数值大小推断\n",
    "- 请仔细识别所有可见的房间、标注、符号和空间关系\n",
    "\n",
    "**分析维度（根据用户问题选择性回答）：**\n",
    "\n",
    "1. **房间/功能区识别**：\n",
    "   - 识别所有房间名称（客厅、卧室、厨房、卫生间、阳台等）\n",
    "   - 标注每个房间的位置（左上/右下/中央等方位）\n",
    "   - 识别特殊功能区（储藏室、玄关、衣帽间等）\n",
    "\n",
    "2. **尺寸与面积**：\n",
    "   - 提取图中所有可见尺寸标注\n",
    "   - 推断单位并统一换算为米(m)\n",
    "   - 计算房间的长、宽、面积\n",
    "   - 标注整体平面外墙尺寸\n",
    "\n",
    "3. **符号与标注**：\n",
    "   - 解释符号含义（虚线、箭头、红点/红线、轴线等）\n",
    "   - 识别文字标注（房间编号、面积、备注）\n",
    "   - 说明墙体类型、门窗位置和开启方向\n",
    "\n",
    "4. **家具布局**：\n",
    "   - 列出所有可见家具及其位置\n",
    "   - 判断空间利用率（拥挤/适中/空旷）\n",
    "   - 识别家具尺寸\n",
    "\n",
    "5. **动线与连通性**：\n",
    "   - 标出主入口、次入口位置\n",
    "   - 描述主要动线路径（如：\"入口→玄关→客厅→...\"）\n",
    "   - 列出房间连通关系（哪些房间相连）\n",
    "   - 判断布局类型（开放式/分隔式）\n",
    "\n",
    "6. **设计评估**（如果问题涉及）：\n",
    "   - 动线合理性、是否有绕行或死角\n",
    "   - 采光/朝向分析\n",
    "   - 空间优化建议\n",
    "\n",
    "**回答方式：**\n",
    "- 首先直接、简洁地回答用户的具体问题\n",
    "- 然后提供相关的详细信息（如果用户问某个房间，重点描述该房间）\n",
    "- 如果用户问整体布局，提供全局分析\n",
    "- 如果涉及尺寸计算，请说明推理过程（如：\"标注22720mm = 22.72m\"）\n",
    "\n",
    "**输出格式（JSON）：**\n",
    "{{\n",
    "    \"answer\": \"直接回答用户问题的核心内容（简洁明了）\",\n",
    "    \"extracted_info\": {{\n",
    "        \"total_dimensions\": {{\n",
    "            \"length\": 22.72,\n",
    "            \"width\": 12.5,\n",
    "            \"unit\": \"m\",\n",
    "            \"total_area\": 284.0\n",
    "        }},\n",
    "        \"rooms\": [\n",
    "            {{\n",
    "                \"name\": \"客厅\",\n",
    "                \"position\": \"中央偏右\",\n",
    "                \"dimensions\": {{\"length\": 5.79, \"width\": 4.2, \"area\": 24.3, \"unit\": \"m\"}},\n",
    "                \"furniture\": [\"沙发\", \"茶几\"],\n",
    "                \"connected_to\": [\"餐厅\", \"卧室1\"],\n",
    "                \"windows\": 2,\n",
    "                \"doors\": 1\n",
    "            }}\n",
    "        ],\n",
    "        \"annotations\": [\n",
    "            {{\"type\": \"dimension\", \"value\": \"22720\", \"parsed_value\": 22.72, \"unit\": \"m\", \"description\": \"外墙总长\"}}\n",
    "        ],\n",
    "        \"symbols\": [\n",
    "            {{\"type\": \"door\", \"count\": 5, \"positions\": [\"客厅-餐厅\", \"卧室1入口\"]}}\n",
    "        ],\n",
    "        \"circulation\": {{\n",
    "            \"main_entrance\": \"底部中央\",\n",
    "            \"main_path\": \"主入口 → 玄关 → 客厅 → 餐厅\",\n",
    "            \"layout_type\": \"开放式客餐厅\"\n",
    "        }},\n",
    "        \"design_notes\": [\"主卧带独立卫生间\", \"动线流畅\"]\n",
    "    }}\n",
    "}}\n",
    "\n",
    "**注意事项：**\n",
    "- 如果标注不清晰，标注为\"不可读\"或给出估算值并说明\n",
    "- 优先回答用户的具体问题，不要罗列所有信息\n",
    "- 如果用户问\"有几个卧室\"，就重点回答卧室数量和位置\n",
    "- 如果用户问\"客厅面积\"，就重点回答客厅的尺寸和面积\n",
    "- 保持答案简洁、针对性强\"\"\"\n",
    "    \n",
    "    def __init__(self, client: OpenAI, model_name: str):\n",
    "        \"\"\"初始化分析器\"\"\"\n",
    "        self.client = client\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def load_image(self, image_path: str) -> Image.Image:\n",
    "        \"\"\"加载本地图片\"\"\"\n",
    "        image_path = Path(image_path)\n",
    "        if not image_path.exists():\n",
    "            raise FileNotFoundError(f\"图片文件不存在: {image_path}\")\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        print(f\"图片加载成功: {image.size}\")\n",
    "        return image\n",
    "    \n",
    "    def image_to_base64(self, image: Image.Image, max_size: int = 2000) -> str:\n",
    "        \"\"\"将PIL Image转换为base64字符串\"\"\"\n",
    "        # 如果图片过大，进行压缩\n",
    "        if image.width > max_size or image.height > max_size:\n",
    "            image = image.copy()\n",
    "            image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)\n",
    "            print(f\"图片已压缩到: {image.size}\")\n",
    "        \n",
    "        # 转换为JPEG格式的base64\n",
    "        buffer = io.BytesIO()\n",
    "        if image.mode == 'RGBA':\n",
    "            image = image.convert('RGB')\n",
    "        image.save(buffer, format='JPEG', quality=85)\n",
    "        buffer.seek(0)\n",
    "        \n",
    "        base64_str = base64.b64encode(buffer.read()).decode('utf-8')\n",
    "        print(f\"图片转换为base64: {len(base64_str) / 1024:.1f} KB\")\n",
    "        return base64_str\n",
    "    \n",
    "    def analyze(self, image_path: str, question: str) -> AnalysisResult:\n",
    "        \"\"\"\n",
    "        分析平面图\n",
    "        \n",
    "        Args:\n",
    "            image_path: 图片路径\n",
    "            question: 用户问题\n",
    "            \n",
    "        Returns:\n",
    "            AnalysisResult对象\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. 加载图片\n",
    "        image = self.load_image(image_path)\n",
    "        \n",
    "        # 2. 转换为base64\n",
    "        image_base64 = self.image_to_base64(image)\n",
    "        \n",
    "        # 3. 构建提示词\n",
    "        prompt = self.FLOOR_PLAN_PROMPT.format(question=question)\n",
    "        \n",
    "        # 4. 调用VLM API\n",
    "        print(\"正在调用VLM模型...\")\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"你是一位专业的建筑平面图分析专家。请仔细分析图像并按照要求的JSON格式返回结果。\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "            max_tokens=4096,\n",
    "            temperature=0.1,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        # 5. 解析响应\n",
    "        content = response.choices[0].message.content\n",
    "        parsed = self._parse_json_response(content)\n",
    "        \n",
    "        print(f\"分析完成！Token使用: {response.usage.total_tokens}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        return AnalysisResult(\n",
    "            answer=parsed.get('answer', ''),\n",
    "            extracted_info=parsed.get('extracted_info', {}),\n",
    "            raw_response=content\n",
    "        )\n",
    "    \n",
    "    def _parse_json_response(self, content: str) -> Dict[str, Any]:\n",
    "        \"\"\"解析JSON响应\"\"\"\n",
    "        try:\n",
    "            # 清理可能的markdown代码块标记\n",
    "            content = content.strip()\n",
    "            if content.startswith('```json'):\n",
    "                content = content[7:]\n",
    "            elif content.startswith('```'):\n",
    "                content = content[3:]\n",
    "            if content.endswith('```'):\n",
    "                content = content[:-3]\n",
    "            content = content.strip()\n",
    "            \n",
    "            return json.loads(content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON解析失败: {e}\")\n",
    "            return {\n",
    "                'answer': content,\n",
    "                'extracted_info': {}\n",
    "            }\n",
    "\n",
    "# 创建平面图分析器\n",
    "analyzer = FloorPlanAnalyzer(vlm_client, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dcd7b4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这段代码是平面图分析系统的核心。让我们理解几个关键点：\n",
    "\n",
    "&emsp;&emsp;**1. 提示词针对平面图优化**\n",
    "\n",
    "&emsp;&emsp;平面图的提示词更加注重：\n",
    "- **房间识别**：客厅、卧室、厨房等功能区\n",
    "- **尺寸推断**：自动判断单位是mm还是m（如22720mm→22.72m）\n",
    "- **动线分析**：入口→玄关→客厅的流动路径\n",
    "- **空间关系**：房间之间的连通性和位置关系\n",
    "\n",
    "&emsp;&emsp;**2. 结构化输出的重要性**\n",
    "\n",
    "&emsp;&emsp;输出的JSON结构包含了<font color=red>完整的户型元数据</font>：\n",
    "- `total_dimensions`：整体尺寸和总面积\n",
    "- `rooms`：每个房间的详细信息（名称、位置、面积、家具）\n",
    "- `circulation`：动线设计和布局类型\n",
    "- `design_notes`：设计特点和建议\n",
    "\n",
    "&emsp;&emsp;这些结构化信息将成为后续智能问答的核心数据源！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a8445",
   "metadata": {},
   "source": [
    "## 5.4 测试平面图分析\n",
    "\n",
    "&emsp;&emsp;接下来让我们测试分析器的功能。\n",
    "\n",
    "> &emsp;**提示**：请准备一张平面图（户型图），替换下面的路径后运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a305c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片加载成功: (900, 781)\n",
      "图片转换为base64: 130.5 KB\n",
      "正在调用VLM模型...\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `gpt-4o` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}, 'request_id': '77df59e2-e3c6-4fe5-b24b-f3a5a8a80785'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m USER_QUESTION = \u001b[33m\"\u001b[39m\u001b[33m请详细分析这张平面图，包括房间布局、尺寸面积、动线设计等信息。\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 执行分析\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43manalyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFLOOR_PLAN_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSER_QUESTION\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 显示分析结果\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.answer)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 185\u001b[39m, in \u001b[36mFloorPlanAnalyzer.analyze\u001b[39m\u001b[34m(self, image_path, question)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m正在调用VLM模型...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    163\u001b[39m messages = [\n\u001b[32m    164\u001b[39m     {\n\u001b[32m    165\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m     }\n\u001b[32m    183\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# 5. 解析响应\u001b[39;00m\n\u001b[32m    194\u001b[39m content = response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/multimodal_rag/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/multimodal_rag/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1156\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1110\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1112\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1153\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1154\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1155\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/multimodal_rag/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/multimodal_rag/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'The model `gpt-4o` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}, 'request_id': '77df59e2-e3c6-4fe5-b24b-f3a5a8a80785'}"
     ]
    }
   ],
   "source": [
    "# ========== 测试平面图分析 ==========\n",
    "\n",
    "# 指定平面图路径（请替换为你的平面图路径）\n",
    "FLOOR_PLAN_PATH = \"./test_data/house1.png\"  # 示例路径\n",
    "\n",
    "# 用户问题\n",
    "USER_QUESTION = \"请详细分析这张平面图，包括房间布局、尺寸面积、动线设计等信息。\"\n",
    "\n",
    "# 执行分析\n",
    "result = analyzer.analyze(FLOOR_PLAN_PATH, USER_QUESTION)\n",
    "\n",
    "# 显示分析结果\n",
    "print(result.answer)\n",
    "print(\"\\n【提取的结构化元数据】\")\n",
    "print(json.dumps(result.extracted_info, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d789ab",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们需要将这些分析结果存储到向量数据库中，以支持高效的检索和问答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb6e26",
   "metadata": {},
   "source": [
    "## 5.4 构建向量数据库存储系统\n",
    "\n",
    "&emsp;&emsp;在多模态RAG系统中，<font color=red>向量数据库</font>扮演着至关重要的角色。它不仅存储了图纸的文本描述，还保存了提取的结构化元数据，使得我们可以：\n",
    "\n",
    "1. **语义检索**：根据用户问题的语义，而非关键词匹配，找到相关图纸\n",
    "2. **元数据过滤**：基于结构化信息（如尺寸、材料等）进行精确筛选\n",
    "3. **高效索引**：即使有成千上万张图纸，也能毫秒级返回结果\n",
    "\n",
    "&emsp;&emsp;向量数据库的核心思想是将文本转换为高维向量（Embedding），相似的文本在向量空间中距离较近。当用户提问时，问题也被转换为向量，然后通过计算距离找到最相关的文档。\n",
    "\n",
    "```\n",
    "    文本内容 → Embedding模型 → 向量表示 → 存储到ChromaDB\n",
    "    用户问题 → Embedding模型 → 问题向量 → 相似度检索 → 返回Top-K结果\n",
    "```\n",
    "\n",
    "&emsp;&emsp;接下来，我们就来实现这个向量存储系统。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d0ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在初始化 Qwen Embedding 模型...\n",
      "✓ 初始化通义千问 Embedding\n",
      "  模型: text-embedding-v4\n",
      "  维度: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量数据库初始化完成\n",
      "✓ 向量数据库管理器已就绪！\n"
     ]
    }
   ],
   "source": [
    "class VectorStoreManager:\n",
    "    \"\"\"向量数据库管理器 - 基于ChromaDB\"\"\"\n",
    "    \n",
    "    def __init__(self, persist_directory: str = \"./chroma_db_floor_plan\"):\n",
    "        \"\"\"初始化向量数据库\"\"\"\n",
    "        self.persist_directory = persist_directory\n",
    "        os.makedirs(persist_directory, exist_ok=True)\n",
    "        \n",
    "        # 初始化 Embedding 模型\n",
    "        print(\"正在初始化 Qwen Embedding 模型...\")\n",
    "        self.embeddings = QwenEmbeddings(\n",
    "            model=\"text-embedding-v4\",\n",
    "            api_key=os.getenv(\"DASHSCOPE_API_KEY\")  # 从环境变量读取\n",
    "        )\n",
    "        \n",
    "        # 初始化 ChromaDB\n",
    "        self.vector_store = Chroma(\n",
    "            persist_directory=persist_directory,\n",
    "            embedding_function=self.embeddings,\n",
    "            collection_name=\"floor_plans\"\n",
    "        )\n",
    "        \n",
    "        # 文本分割器\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \"。\", \".\", \" \", \"\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"向量数据库初始化完成\")\n",
    "    \n",
    "    def add_document(\n",
    "        self,\n",
    "        file_id: str,\n",
    "        file_name: str,\n",
    "        content: str,\n",
    "        extracted_info: Dict[str, Any]\n",
    "    ) -> int:\n",
    "        \"\"\"添加户型文档到向量库\"\"\"\n",
    "        print(f\"\\n添加文档到向量库: {file_name}\")\n",
    "        \n",
    "        # 1. 分割文本\n",
    "        chunks = self.text_splitter.split_text(content)\n",
    "        print(f\"  文本分割为 {len(chunks)} 个块\")\n",
    "        \n",
    "        # 2. 创建Document对象\n",
    "        documents = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            metadata = {\n",
    "                \"file_id\": file_id,\n",
    "                \"file_name\": file_name,\n",
    "                \"chunk_id\": i,\n",
    "                \"total_chunks\": len(chunks),\n",
    "                \"extracted_info_json\": json.dumps(extracted_info, ensure_ascii=False)\n",
    "            }\n",
    "            \n",
    "            # 提取关键字段到元数据顶层（便于过滤和问答）\n",
    "            if \"total_dimensions\" in extracted_info:\n",
    "                dims = extracted_info[\"total_dimensions\"]\n",
    "                metadata[\"total_area\"] = float(dims.get(\"total_area\", 0))\n",
    "                metadata[\"total_length\"] = float(dims.get(\"length\", 0))\n",
    "                metadata[\"total_width\"] = float(dims.get(\"width\", 0))\n",
    "            \n",
    "            if \"rooms\" in extracted_info:\n",
    "                rooms = extracted_info[\"rooms\"]\n",
    "                metadata[\"room_count\"] = len(rooms)\n",
    "                # 统计卧室数量\n",
    "                bedrooms = [r for r in rooms if \"卧\" in r.get(\"name\", \"\")]\n",
    "                metadata[\"bedroom_count\"] = len(bedrooms)\n",
    "            \n",
    "            if \"circulation\" in extracted_info:\n",
    "                circ = extracted_info[\"circulation\"]\n",
    "                metadata[\"layout_type\"] = circ.get(\"layout_type\", \"\")\n",
    "            \n",
    "            documents.append(Document(\n",
    "                page_content=chunk,\n",
    "                metadata=metadata\n",
    "            ))\n",
    "        \n",
    "        # 3. 添加到向量库\n",
    "        ids = [f\"{file_id}_chunk_{i}\" for i in range(len(documents))]\n",
    "        self.vector_store.add_documents(documents, ids=ids)\n",
    "        \n",
    "        print(f\"文档已添加，共 {len(documents)} 个文本块\")\n",
    "        return len(documents)\n",
    "    \n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        top_k: int = 5\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"向量检索\"\"\"\n",
    "        print(f\"\\n执行向量检索: {query[:50]}...\")\n",
    "        \n",
    "        # 执行相似度检索\n",
    "        results = self.vector_store.similarity_search_with_score(\n",
    "            query,\n",
    "            k=top_k\n",
    "        )\n",
    "        \n",
    "        # 格式化结果\n",
    "        formatted_results = []\n",
    "        for doc, score in results:\n",
    "            formatted_results.append({\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"similarity\": float(1 - score)\n",
    "            })\n",
    "        \n",
    "        print(f\"✓ 找到 {len(formatted_results)} 个相关结果\")\n",
    "        return formatted_results\n",
    "\n",
    "\n",
    "# 创建向量数据库管理器\n",
    "vector_manager = VectorStoreManager()\n",
    "print(\"✓ 向量数据库管理器已就绪！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503686b2",
   "metadata": {},
   "source": [
    "## 5.5 智能问答\n",
    "\n",
    "&emsp;&emsp;这里我们将实现两种问答模式：\n",
    "\n",
    "1. **直接问答**：从元数据直接提取答案（如\"有几个卧室？\"、\"客厅多大？\"）\n",
    "2. **图像检索**：返回相关户型列表（如\"找3室2厅的户型\"）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3cc53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM智能问答系统已就绪！\n"
     ]
    }
   ],
   "source": [
    "class IntelligentQA:\n",
    "    \"\"\"智能问答系统 - LLM驱动版本\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_manager: VectorStoreManager, llm_client: OpenAI, model_name: str):\n",
    "        self.vector_manager = vector_manager\n",
    "        self.llm_client = llm_client\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def direct_answer(self, question: str, top_k: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"使用LLM基于元数据生成答案\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"LLM智能问答模式\")\n",
    "        print(f\"   问题: {question}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. 向量检索\n",
    "        results = self.vector_manager.search(question, top_k=top_k)\n",
    "        \n",
    "        if not results:\n",
    "            return {\n",
    "                \"answer\": \"抱歉，没有找到相关户型信息。\",\n",
    "                \"sources\": [],\n",
    "                \"mode\": \"direct_answer\"\n",
    "            }\n",
    "        \n",
    "        # 2. 收集所有相关的元数据\n",
    "        context_parts = []\n",
    "        for i, result in enumerate(results):\n",
    "            metadata = result[\"metadata\"]\n",
    "            \n",
    "            # 解析结构化信息\n",
    "            extracted_info = {}\n",
    "            if \"extracted_info_json\" in metadata:\n",
    "                try:\n",
    "                    extracted_info = json.loads(metadata[\"extracted_info_json\"])\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            context_parts.append(f\"\"\"\n",
    "文档 {i+1}：{metadata.get('file_name', '未知文件')}\n",
    "VLM描述：{result['content']}\n",
    "结构化数据：{json.dumps(extracted_info, ensure_ascii=False, indent=2)}\n",
    "相似度：{result['similarity']:.2f}\n",
    "\"\"\")\n",
    "        \n",
    "        # 3. 构建LLM提示词\n",
    "        context = \"\\n\".join(context_parts)\n",
    "        \n",
    "        prompt = f\"\"\"你是一个专业的房产顾问，请根据提供的户型信息回答用户问题。\n",
    "\n",
    "用户问题：{question}\n",
    "\n",
    "可用的户型信息：\n",
    "{context}\n",
    "\n",
    "请根据以上信息回答用户问题，要求：\n",
    "1. 直接、准确地回答问题\n",
    "2. 如果涉及具体数据（面积、尺寸等），请引用准确数值\n",
    "3. 如果问题涉及多个户型，请进行对比\n",
    "4. 保持回答简洁明了\n",
    "5. 在回答末尾注明信息来源\n",
    "\n",
    "回答：\"\"\"\n",
    "\n",
    "        # 4. 调用LLM生成答案\n",
    "        print(\"正在调用LLM生成智能答案...\")\n",
    "        response = self.llm_client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一个专业的房产顾问，擅长分析户型信息并回答客户问题。\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=1000,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        print(f\"LLM答案生成完成！\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"sources\": [{\n",
    "                \"file_id\": result[\"metadata\"].get(\"file_id\"),\n",
    "                \"file_name\": result[\"metadata\"].get(\"file_name\"),\n",
    "                \"similarity\": result[\"similarity\"]\n",
    "            } for result in results],\n",
    "            \"mode\": \"direct_answer\"\n",
    "        }\n",
    "    \n",
    "    def search_images(self, query: str, top_k: int = 5) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        图像检索模式 - 也用LLM来生成更智能的检索结果描述\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"LLM智能检索模式\")\n",
    "        print(f\"   查询: {query}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. 向量检索\n",
    "        results = self.vector_manager.search(query, top_k=top_k * 2)\n",
    "        \n",
    "        if not results:\n",
    "            return {\n",
    "                \"message\": f\"没有找到与 '{query}' 相关的户型。\",\n",
    "                \"images\": [],\n",
    "                \"mode\": \"search_images\"\n",
    "            }\n",
    "        \n",
    "        # 2. 按文件聚合（去重）\n",
    "        file_map = {}\n",
    "        for result in results:\n",
    "            file_id = result[\"metadata\"].get(\"file_id\")\n",
    "            if file_id not in file_map:\n",
    "                # 解析结构化信息\n",
    "                extracted_info = {}\n",
    "                if \"extracted_info_json\" in result[\"metadata\"]:\n",
    "                    try:\n",
    "                        extracted_info = json.loads(result[\"metadata\"][\"extracted_info_json\"])\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                file_map[file_id] = {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"file_name\": result[\"metadata\"].get(\"file_name\"),\n",
    "                    \"similarity\": result[\"similarity\"],\n",
    "                    \"content\": result[\"content\"],\n",
    "                    \"extracted_info\": extracted_info,\n",
    "                    \"metadata\": result[\"metadata\"]\n",
    "                }\n",
    "            else:\n",
    "                # 更新最高相似度\n",
    "                if result[\"similarity\"] > file_map[file_id][\"similarity\"]:\n",
    "                    file_map[file_id][\"similarity\"] = result[\"similarity\"]\n",
    "        \n",
    "        # 3. 按相似度排序\n",
    "        sorted_files = sorted(\n",
    "            file_map.values(),\n",
    "            key=lambda x: x[\"similarity\"],\n",
    "            reverse=True\n",
    "        )[:top_k]\n",
    "        \n",
    "        # 4. 用LLM生成智能的检索结果描述\n",
    "        files_info = []\n",
    "        for file_info in sorted_files:\n",
    "            files_info.append({\n",
    "                \"file_name\": file_info[\"file_name\"],\n",
    "                \"similarity\": file_info[\"similarity\"],\n",
    "                \"description\": file_info[\"content\"],\n",
    "                \"details\": file_info[\"extracted_info\"]\n",
    "            })\n",
    "        \n",
    "        search_prompt = f\"\"\"作为房产顾问，请根据检索到的户型信息，回答用户的查询需求。\n",
    "\n",
    "用户查询：{query}\n",
    "\n",
    "检索到的户型：\n",
    "{json.dumps(files_info, ensure_ascii=False, indent=2)}\n",
    "\n",
    "请：\n",
    "1. 总结找到了几个相关户型\n",
    "2. 对每个户型进行简要介绍（户型、面积、特点等）\n",
    "3. 根据用户查询给出推荐意见\n",
    "4. 保持专业和友好的语调\n",
    "\n",
    "回答：\"\"\"\n",
    "\n",
    "        print(\"正在生成智能检索结果...\")\n",
    "        response = self.llm_client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是专业的房产顾问，擅长根据客户需求推荐合适的户型。\"},\n",
    "                {\"role\": \"user\", \"content\": search_prompt}\n",
    "            ],\n",
    "            max_tokens=1000,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        message = response.choices[0].message.content\n",
    "        \n",
    "        print(f\"✓ 找到 {len(sorted_files)} 个相关户型\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            \"message\": message,\n",
    "            \"images\": [{\n",
    "                \"file_id\": f[\"file_id\"],\n",
    "                \"file_name\": f[\"file_name\"], \n",
    "                \"similarity\": f[\"similarity\"]\n",
    "            } for f in sorted_files],\n",
    "            \"mode\": \"search_images\"\n",
    "        }\n",
    "\n",
    "    def ask(self, question: str, mode: str = \"auto\") -> Dict[str, Any]:\n",
    "        \"\"\"统一问答接口\"\"\"\n",
    "        # 智能判断模式\n",
    "        if mode == \"auto\":\n",
    "            search_keywords = [\"找\", \"有没有\", \"哪些\", \"查找\", \"搜索\", \"推荐\", \"比较\"]\n",
    "            if any(kw in question for kw in search_keywords):\n",
    "                return self.search_images(question)\n",
    "            else:\n",
    "                return self.direct_answer(question)\n",
    "        \n",
    "        if mode == \"direct_answer\":\n",
    "            return self.direct_answer(question)\n",
    "        elif mode == \"search_images\":\n",
    "            return self.search_images(question)\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的模式: {mode}\")\n",
    "\n",
    "\n",
    "# 重新创建问答系统\n",
    "qa_system = IntelligentQA(vector_manager, vlm_client, MODEL_NAME)\n",
    "print(\"LLM智能问答系统已就绪！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e3918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓图片加载成功: (900, 781)\n",
      "图片转换为base64: 130.5 KB\n",
      "正在调用VLM模型...\n",
      "分析完成！Token使用: 2762\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 分析平面图\n",
    "image_path = \"./test_data/house1.png\"\n",
    "question = \"请详细分析这张平面图，包括房间布局、尺寸、动线等信息。\"\n",
    "result = analyzer.analyze(image_path, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98fe55a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【分析结果】\n",
      "这张平面图展示了一套三居室的住宅布局，包含客厅、主卧、次卧、儿童房、厨房、主卫、次卫和阳台等功能区。整体布局紧凑，动线合理。\n",
      "\n",
      "【提取的元数据】\n",
      "{\n",
      "  \"total_dimensions\": {\n",
      "    \"length\": 12.949,\n",
      "    \"width\": 9.192,\n",
      "    \"unit\": \"m\",\n",
      "    \"total_area\": 119.0\n",
      "  },\n",
      "  \"rooms\": [\n",
      "    {\n",
      "      \"name\": \"客厅\",\n",
      "      \"position\": \"中央偏左\",\n",
      "      \"dimensions\": {\n",
      "        \"length\": 5.198,\n",
      "        \"width\": 3.188,\n",
      "        \"area\": 16.58,\n",
      "        \"unit\": \"m\"\n",
      "      },\n",
      "      \"furniture\": [\n",
      "        \"沙发\",\n",
      "        \"茶几\",\n",
      "        \"电视柜\"\n",
      "      ],\n",
      "      \"connected_to\": [\n",
      "        \"餐厅\",\n",
      "        \"阳台\"\n",
      "      ],\n",
      "      \"windows\": 1,\n",
      "      \"doors\": 1\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"主卧\",\n",
      "      \"position\": \"左下角\",\n",
      "      \"dimensions\": {\n",
      "        \"length\": 3.617,\n",
      "        \"width\": 4.113,\n",
      "        \"area\": 14.88,\n",
      "        \"unit\": \"m\"\n",
      "      },\n",
      "      \"furniture\": [\n",
      "        \"床\",\n",
      "        \"衣柜\"\n",
      "      ],\n",
      "      \"connected_to\": [\n",
      "        \"主卫\"\n",
      "      ],\n",
      "      \"windows\": 1,\n",
      "      \"doors\": 1\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"次卧\",\n",
      "      \"position\": \"右上角\",\n",
      "      \"dimensions\": {\n",
      "        \"length\": 3.499,\n",
      "        \"width\": 3.188,\n",
      "        \"area\": 11.15,\n",
      "        \"unit\": \"m\"\n",
      "      },\n",
      "      \"furniture\": [\n",
      "        \"床\",\n",
      "        \"衣柜\"\n",
      "      ],\n",
      "      \"connected_to\": [\n",
      "        \"次卫\"\n",
      "      ],\n",
      "      \"windows\": 1,\n",
      "      \"doors\": 1\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"儿童房\",\n",
      "      \"position\": \"左上角\",\n",
      "      \"dimensions\": {\n",
      "        \"length\": 3.617,\n",
      "        \"width\": 3.127,\n",
      "        \"area\": 11.31,\n",
      "        \"unit\": \"m\"\n",
      "      },\n",
      "      \"furniture\": [\n",
      "        \"床\",\n",
      "        \"衣柜\"\n",
      "      ],\n",
      "      \"connected_to\": [\n",
      "        \"厨房\"\n",
      "      ],\n",
      "      \"windows\": 1,\n",
      "      \"doors\": 1\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"厨房\",\n",
      "      \"position\": \"中央偏上\",\n",
      "      \"dimensions\": {\n",
      "        \"length\": 2.733,\n",
      "        \"width\": 2.49,\n",
      "        \"area\": 6.8,\n",
      "        \"unit\": \"m\"\n",
      "      },\n",
      "      \"furniture\": [\n",
      "        \"橱柜\",\n",
      "        \"灶台\"\n",
      "      ],\n",
      "      \"connected_to\": [\n",
      "        \"儿童房\",\n",
      "        \"次卫\"\n",
      "      ],\n",
      "      \"windows\": 1,\n",
      "      \"doors\": 1\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"主卫\",\n",
      "      \"position\": \"左下角\",\n",
      "      \"dimensions\": {\n",
      "        \"length\": 2.22,\n",
      "        \"width\": 1.8,\n",
      "        \"area\": 3.996,\n",
      "        \"unit\": \"m\"\n",
      "      },\n",
      "      \"furniture\": [\n",
      "        \"浴缸\",\n",
      "        \"洗手台\"\n",
      "      ],\n",
      "      \"connected_to\": [\n",
      "        \"主卧\"\n",
      "      ],\n",
      "      \"windows\": 0,\n",
      "      \"doors\": 1\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"次卫\",\n",
      "      \"position\": \"右上角\",\n",
      "      \"dimensions\": {\n",
      "        \"length\": 2.49,\n",
      "        \"width\": 1.5,\n",
      "        \"area\": 3.735,\n",
      "        \"unit\": \"m\"\n",
      "      },\n",
      "      \"furniture\": [\n",
      "        \"淋浴\",\n",
      "        \"洗手台\"\n",
      "      ],\n",
      "      \"connected_to\": [\n",
      "        \"次卧\",\n",
      "        \"厨房\"\n",
      "      ],\n",
      "      \"windows\": 0,\n",
      "      \"doors\": 1\n",
      "    }\n",
      "  ],\n",
      "  \"annotations\": [\n",
      "    {\n",
      "      \"type\": \"dimension\",\n",
      "      \"value\": \"12949\",\n",
      "      \"parsed_value\": 12.949,\n",
      "      \"unit\": \"m\",\n",
      "      \"description\": \"外墙总长\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"dimension\",\n",
      "      \"value\": \"9192\",\n",
      "      \"parsed_value\": 9.192,\n",
      "      \"unit\": \"m\",\n",
      "      \"description\": \"外墙总宽\"\n",
      "    }\n",
      "  ],\n",
      "  \"symbols\": [\n",
      "    {\n",
      "      \"type\": \"door\",\n",
      "      \"count\": 7,\n",
      "      \"positions\": [\n",
      "        \"客厅-餐厅\",\n",
      "        \"主卧-主卫\",\n",
      "        \"次卧-次卫\",\n",
      "        \"儿童房-厨房\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"circulation\": {\n",
      "    \"main_entrance\": \"右下角\",\n",
      "    \"main_path\": \"主入口 → 玄关 → 客厅 → 各房间\",\n",
      "    \"layout_type\": \"分隔式\"\n",
      "  },\n",
      "  \"design_notes\": [\n",
      "    \"主卧带独立卫生间\",\n",
      "    \"动线流畅\",\n",
      "    \"客厅与餐厅相连\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"【分析结果】\")\n",
    "print(result.answer)\n",
    "print(\"\\n【提取的元数据】\")\n",
    "print(json.dumps(result.extracted_info, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fe934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "添加文档到向量库: house1.png\n",
      "  文本分割为 1 个块\n",
      "文档已添加，共 1 个文本块\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# 2. 存储到向量数据库\n",
    "file_id = str(uuid.uuid4())\n",
    "file_name = \"house1.png\"\n",
    "chunk_count = vector_manager.add_document(\n",
    "    file_id=file_id,\n",
    "    file_name=file_name,\n",
    "    content=result.answer,  # 将VLM的回答作为文本内容\n",
    "    extracted_info=result.extracted_info  # 结构化的元数据\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db17f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "户型已成功存入向量数据库！\n",
      "  文件ID: d7ea1633-51f4-433c-8b9a-0cc1ba813e21\n",
      "  文本块数: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n户型已成功存入向量数据库！\")\n",
    "print(f\"  文件ID: {file_id}\")\n",
    "print(f\"  文本块数: {chunk_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0ccb732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LLM智能问答模式\n",
      "   问题: 这个户型有几个卧室？\n",
      "============================================================\n",
      "\n",
      "执行向量检索: 这个户型有几个卧室？...\n",
      "✓ 找到 3 个相关结果\n",
      "正在调用LLM生成智能答案...\n",
      "LLM答案生成完成！\n",
      "============================================================\n",
      "回答：这个户型有三个卧室，分别是主卧、次卧和儿童房。\n",
      "\n",
      "信息来源：文档 1、文档 2、文档 3。\n"
     ]
    }
   ],
   "source": [
    "# 示例1：直接问答\n",
    "result1 = qa_system.ask(\"这个户型有几个卧室？\")\n",
    "\n",
    "print(f\"回答：{result1['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5785b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LLM智能检索模式\n",
      "   查询: 找一下有没有3室2厅的户型？\n",
      "============================================================\n",
      "\n",
      "执行向量检索: 找一下有没有3室2厅的户型？...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 找到 3 个相关结果\n",
      "正在生成智能检索结果...\n",
      "✓ 找到 3 个相关户型\n",
      "============================================================\n",
      "\n",
      "问题：找一下有没有3室2厅的户型？\n",
      "回答：感谢您的查询！根据您的需求，我们找到了三个符合条件的3室2厅的户型。以下是每个户型的简要介绍：\n",
      "\n",
      "1. **户型一**\n",
      "   - **面积**: 总面积为119平方米。\n",
      "   - **特点**: 该户型布局紧凑，动线合理，包含客厅、主卧、次卧、儿童房、厨房、主卫、次卫和阳台等功能区。主卧带有独立卫生间，客厅与餐厅相连，采光良好。\n",
      "\n",
      "2. **户型二**\n",
      "   - **面积**: 总面积为119平方米。\n",
      "   - **特点**: 该户型设计为分隔式布局，包含客厅、主卧、次卧、儿童房、厨房、主卫、次卫、餐厅和入户玄关。主卧同样带有独立卫生间，客餐厅一体化设计，动线流畅。\n",
      "\n",
      "3. **户型三**\n",
      "   - **面积**: 总面积为119平方米。\n",
      "   - **特点**: 该户型为开放式布局，客厅和餐厅连通，动线流畅。包含客厅、主卧、次卧、儿童房、厨房、主卫、次卫和入户玄关。主卧带有独立卫生间，采光良好。\n",
      "\n",
      "**推荐意见**:\n",
      "根据您的需求，这三个户型都符合3室2厅的标准，并且每个户型都有其独特的设计特点。若您偏好动线流畅且采光良好的设计，户型三可能是一个不错的选择。若您更注重客餐厅一体化设计，户型二则可能更适合您。希望这些信息能帮助您做出更好的选择！\n",
      "\n",
      "如需进一步了解或预约看房，请随时与我们联系。我们很乐意为您提供更多帮助！\n"
     ]
    }
   ],
   "source": [
    "result2 = qa_system.ask(\"找一下有没有3室2厅的户型？\")\n",
    "print(f\"\\n问题：找一下有没有3室2厅的户型？\")\n",
    "print(f\"回答：{result2['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf9f1f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据实际的应用场景，我们实现了两种互补的问答模式：\n",
    "- **直接问答**：适合需要快速获取精确信息的场景（如查询材料、尺寸等）\n",
    "- **图像检索**：适合需要浏览和对比多个图纸的场景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a92ec32",
   "metadata": {},
   "source": [
    "# 六、企业项目实战：多模态RAG项目本地部署"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5171ed",
   "metadata": {},
   "source": [
    "<center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151407213.png\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc66c7a0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "&emsp;&emsp;本节内容，我们将详细介绍如何部署和运行这个**基于VLM的多模态RAG智能问答系统**。该系统支持CAD图纸、平面图、架构图、PDF文档等多种格式的智能分析和问答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c4182",
   "metadata": {},
   "source": [
    "## 6.1 项目结构详解\n",
    "\n",
    "&emsp;&emsp;项目采用模块化设计，核心结构如下：\n",
    "\n",
    "```\n",
    "    pc_multimodal_rag/                    # 项目根目录\n",
    "    ├── 📁 backend/                       # 后端服务层\n",
    "    │   ├── main_service.py              # FastAPI主服务 - 多模态RAG API\n",
    "    │   ├── simple_vlm_analyzer.py       # VLM图像分析器 (支持CAD/平面图/架构图)\n",
    "    │   ├── qwen_embeddings.py           # 通义千问Embedding模型封装\n",
    "    │   ├── simple_logger.py             # 日志记录模块\n",
    "    │   ├── 📁 unified/                   # 统一PDF处理模块\n",
    "    │   │   └── unified_pdf_extraction_service.py  # PDF解析服务\n",
    "    │   ├── 📁 Information-Extraction/    # 信息提取模块\n",
    "    │   ├── 📁 image_analysis/            # 图像分析模块\n",
    "    │   └── 📁 chroma_db/                 # ChromaDB向量数据库存储\n",
    "    │\n",
    "    ├── 📁 frontend/                      # 前端界面 (可选)\n",
    "    ├── 📁 uploads/                       # 上传文件存储目录\n",
    "    ├── 📁 previews/                      # 文件预览/缩略图存储\n",
    "    ├── 📁 test_data/                     # 测试数据\n",
    "    └── .env                              # 环境配置文件\n",
    "```\n",
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "<p align=\"center\"><font face=\"黑体\" size=4>核心组件功能说明</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| 层级 | 技术栈 | 主要功能 | 关键文件 |\n",
    "|-----|-------|----------|----------|\n",
    "| **API服务层** | FastAPI + Pydantic | RESTful API、文件上传、智能问答 | `main_service.py` |\n",
    "| **VLM分析层** | 多模态大模型 + 自定义提示词 | 多模态理解、图像分析、结构化提取 | `simple_vlm_analyzer.py` |\n",
    "| **向量检索层** | ChromaDB + Qwen/HuggingFace Embeddings | 语义检索、相似度计算 | `qwen_embeddings.py` + ChromaDB |\n",
    "| **文档处理层** | PyMuPDF + PIL + 自定义解析器 | PDF解析、图像预处理、格式转换 | `unified_pdf_extraction_service.py` |\n",
    "| **数据存储层** | 文件系统 + 向量数据库 | 原文件存储、向量索引、元数据管理 | `uploads/` + `chroma_db/` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e200b",
   "metadata": {},
   "source": [
    "## 6.2 环境要求与依赖安装\n",
    "\n",
    "&emsp;&emsp;系统基于Python 3.11+开发，需要确保环境满足以下要求：\n",
    "\n",
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "<p align=\"center\"><font face=\"黑体\" size=4>环境要求</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| 组件 | 版本要求 | 安装方式 | 验证命令 |\n",
    "|-----|---------|---------|---------| \n",
    "| **Python** | ≥ 3.10 | 官网下载或conda | `python --version` |\n",
    "| **pip** | 最新版 | 随Python安装 | `pip --version` |\n",
    "\n",
    "&emsp;&emsp;首先需要创建Python虚拟环境\n",
    "\n",
    "```bash\n",
    "# 使用conda创建环境（推荐）\n",
    "conda create -n multimodal_rag python=3.11\n",
    "conda activate multimodal_rag\n",
    "\n",
    "# 或使用venv创建环境\n",
    "python -m venv multimodal_rag\n",
    "source multimodal_rag/bin/activate  # Linux/Mac\n",
    "# multimodal_rag\\\\Scripts\\\\activate     # Windows\n",
    "```\n",
    "\n",
    "&emsp;&emsp;接下来一键安装核心依赖\n",
    "\n",
    "```bash\n",
    "# 进入项目目录\n",
    "cd pc_multimodal_rag/backend\n",
    "\n",
    "# 安装核心依赖包\n",
    "pip install -r requirements_service.txt\n",
    "```\n",
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151017803.png\" style=\"zoom:80%;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b6116",
   "metadata": {},
   "source": [
    "## 6.3 后端服务配置与启动\n",
    "\n",
    "&emsp;&emsp;完成依赖安装后，需要配置API密钥和启动后端服务。\n",
    "\n",
    "&emsp;&emsp;<font color=red>创建 `.env` 文件</font>，配置必要的API密钥：\n",
    "\n",
    "```bash\n",
    "# 在项目根目录创建 .env 文件\n",
    "touch .env\n",
    "```\n",
    "\n",
    "&emsp;&emsp;在 `.env` 文件中添加以下配置：\n",
    "\n",
    "```env\n",
    "    # 多模态 RAG 服务配置\n",
    "\n",
    "    # VLM 模型配置\n",
    "    VLM_MODEL_URL=https:/\n",
    "    VLM_API_KEY=sk-Y4o8DF6Iq2l8nFT\n",
    "    VLM_MODEL_NAME=gpt-4o\n",
    "\n",
    "    # 服务配置\n",
    "    SERVICE_HOST=0.0.0.0\n",
    "    SERVICE_PORT=8000\n",
    "\n",
    "    # 存储配置\n",
    "    UPLOAD_DIR=./uploads\n",
    "    PREVIEW_DIR=./previews\n",
    "    VECTOR_DB_DIR=./chroma_db\n",
    "\n",
    "    # Embedding 模型配置\n",
    "    EMBEDDING_TYPE=qwen  # qwen 或 huggingface\n",
    "    EMBEDDING_MODEL=text-embedding-v4\n",
    "    EMBEDDING_DIMENSIONS=1024\n",
    "    DASHSCOPE_API_KEY=sk-bdccf7277a5\n",
    "    DASHSCOPE_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1\n",
    "\n",
    "    # 文本分割配置\n",
    "    CHUNK_SIZE=800\n",
    "    CHUNK_OVERLAP=100\n",
    "```\n",
    "\n",
    "&emsp;&emsp;<font color=red>重要提示：</font>\n",
    "- `OPENAI_API_KEY`：必须配置，用于调用gpt-4o模型进行图像分析\n",
    "- `DASHSCOPE_API_KEY`：必须配置，用于调用Qwen embedding模型\n",
    "- 如果使用HuggingFace模型，可以不配置`DASHSCOPE_API_KEY`\n",
    "\n",
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151017804.png\" style=\"zoom:80%;\" />\n",
    "\n",
    "&emsp;&emsp;接下来启动后端服务\n",
    "\n",
    "```bash\n",
    "# 启动FastAPI后端服务\n",
    "python backend/main_service.py\n",
    "```\n",
    "\n",
    "&emsp;&emsp;启动成功后，终端会显示如下信息：\n",
    "\n",
    "```\n",
    "INFO:     Started server process [12345]  \n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
    "```\n",
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151017805.png\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafde3b",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "<p align=\"center\"><font face=\"黑体\" size=4>核心组件功能说明</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| 接口路径 | 方法 | 功能 | 说明 |\n",
    "|---------|------|------|------|\n",
    "| `/upload/` | POST | 文件上传 | 支持图片、PDF等多种格式 |\n",
    "| `/search/` | POST | 智能搜索 | 基于向量检索的语义搜索 |\n",
    "| `/intelligent_qa/` | POST | 智能问答 | 多模态问答，支持直接回答和图像检索 |\n",
    "| `/files/` | GET | 文件列表 | 获取已上传的文件列表 |\n",
    "\n",
    "\n",
    "## 6.4 前端服务配置与启动\n",
    "\n",
    "&emsp;&emsp;最后，启动前端服务，进入前端目录，安装Node.js依赖，启动开发服务器：\n",
    "\n",
    "```bash\n",
    "    cd frontend\n",
    "    npm install\n",
    "```\n",
    "<center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151021373.png\" style=\"zoom:80%;\" />\n",
    "\n",
    "```bash\n",
    "    npm run dev\n",
    "```\n",
    "\n",
    "<center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151021374.png\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b13689",
   "metadata": {},
   "source": [
    "\n",
    "&emsp;&emsp;打开浏览器访问 http://localhost:5173，就可以看到\"赋范空间公开体验课\"的界面。\n",
    "\n",
    "<center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202510151021375.png\" style=\"zoom:80%;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb0db6e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，多模态RAG系统部署完成！系统支持CAD图纸、平面图、PDF文档的智能分析和问答，可根据实际需求进行功能扩展和定制开发。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
